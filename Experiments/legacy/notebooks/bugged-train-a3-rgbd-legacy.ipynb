{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14542234,"sourceType":"datasetVersion","datasetId":9288121}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"header-cell","cell_type":"markdown","source":"# A.3 - RGB+Depth (Real) 4-Channel Training\n\n**Experiment:** A.3  \n**Input:** RGB+Depth (4-channel RGBD)  \n**Objective:** Test fusion of RGB and real depth data  \n**Classes:** 1 (fresh_fruit_bunch)\n\n## Workflow\n1. Load RGBD dataset (4-channel images, YOLO format)\n2. Train YOLOv11n with 5 seeds (42, 123, 456, 789, 101)\n3. Evaluate on test set\n4. Calculate mean ¬± std deviation\n\n## Training Config\n- Model: YOLOv11n (modified for 4-channel input)\n- Epochs: 100\n- Patience: 30\n- Other parameters: default\n\n## Dataset Structure\n- Images: 4-channel PNG (R, G, B, Depth)\n- Depth channel: normalized 0-255","metadata":{}},{"id":"setup-cell","cell_type":"code","source":"# =============================================================================\n# Cell 1: Setup + Merge RGB+Depth into 4-Channel Images\n# =============================================================================\nimport os\nimport torch\nimport numpy as np\nimport cv2\nimport shutil\nfrom pathlib import Path\nfrom datetime import datetime\n\nIS_KAGGLE = os.path.exists('/kaggle/input')\nprint(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n\n# Paths\nDATASET_PATH = Path('/kaggle/input/ffb-localization-rgbd-dataset/ffb_localization_rgbd')\nBASE_PATH = Path('/kaggle/working')\nRUNS_PATH = BASE_PATH / 'runs' / 'detect'\nKAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\nKAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Dataset: {DATASET_PATH} (exists: {DATASET_PATH.exists()})\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n# =============================================================================\n# Verify Original Dataset Structure (RGB, Depth, Labels)\n# =============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"ORIGINAL DATASET STRUCTURE\")\nprint(\"=\"*60)\n\nfor split in ['train', 'val', 'test']:\n    rgb_count = len(list((DATASET_PATH / 'rgb' / split).glob('*.png')))\n    depth_count = len(list((DATASET_PATH / 'depth' / split).glob('*.png')))\n    label_count = len(list((DATASET_PATH / 'labels' / split).glob('*.txt')))\n    print(f\"  {split}: {rgb_count} RGB, {depth_count} Depth, {label_count} labels\")\n\n# =============================================================================\n# Merge RGB + Depth into 4-Channel RGBD Images\n# =============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"MERGING RGB + DEPTH INTO 4-CHANNEL IMAGES\")\nprint(\"=\"*60)\n\ndef merge_rgbd(rgb_dir, depth_dir, output_dir):\n    \"\"\"\n    Merge RGB and Depth into 4-channel RGBD images\n    \n    Args:\n        rgb_dir: Path to RGB images folder\n        depth_dir: Path to Depth images folder\n        output_dir: Path to output 4-channel images folder\n    \n    Returns:\n        Number of images merged\n    \"\"\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    rgb_files = sorted(rgb_dir.glob('*.png'))\n    \n    if len(rgb_files) == 0:\n        print(f\"  WARNING: No RGB images found in {rgb_dir}\")\n        return 0\n    \n    for rgb_file in rgb_files:\n        # Load RGB image (BGR in OpenCV)\n        rgb = cv2.imread(str(rgb_file), cv2.IMREAD_COLOR)\n        if rgb is None:\n            print(f\"  ERROR: Cannot read {rgb_file}\")\n            continue\n        \n        # Load Depth image (single channel)\n        depth_file = depth_dir / rgb_file.name\n        depth = cv2.imread(str(depth_file), cv2.IMREAD_GRAYSCALE)\n        if depth is None:\n            print(f\"  ERROR: Cannot read {depth_file}\")\n            continue\n        \n        # Merge BGR (3 channels) + Depth (1 channel) = BGRD (4 channels)\n        rgbd = cv2.merge([rgb[:,:,0], rgb[:,:,1], rgb[:,:,2], depth])\n        \n        # Save as 4-channel PNG\n        output_file = output_dir / rgb_file.name\n        cv2.imwrite(str(output_file), rgbd)\n    \n    return len(rgb_files)\n\n# Create merged images directory\nMERGED_IMAGES_PATH = BASE_PATH / 'images_rgbd'\n\n# Merge for train, val, test splits\nmerged_counts = {}\nfor split in ['train', 'val', 'test']:\n    rgb_dir = DATASET_PATH / 'rgb' / split\n    depth_dir = DATASET_PATH / 'depth' / split\n    output_dir = MERGED_IMAGES_PATH / split\n    \n    count = merge_rgbd(rgb_dir, depth_dir, output_dir)\n    merged_counts[split] = count\n    print(f\"  {split}: merged {count} images\")\n\n# =============================================================================\n# Verify Merged 4-Channel Images\n# =============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"VERIFICATION: 4-CHANNEL MERGED IMAGES\")\nprint(\"=\"*60)\n\nfor split in ['train', 'val', 'test']:\n    img_path = MERGED_IMAGES_PATH / split\n    img_files = list(img_path.glob('*.png'))\n    \n    if len(img_files) == 0:\n        print(f\"  {split}: 0 images\")\n        continue\n    \n    # Check first image\n    sample_img = cv2.imread(str(img_files[0]), cv2.IMREAD_UNCHANGED)\n    if sample_img is not None:\n        print(f\"  {split}: {len(img_files)} images, shape={sample_img.shape} (H√óW√óChannels)\")\n        assert sample_img.shape[2] == 4, f\"Expected 4 channels, got {sample_img.shape[2]}\"\n    else:\n        print(f\"  {split}: Failed to read sample image\")\n\n# =============================================================================\n# Copy Labels to Merged Dataset Folder\n# =============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"COPYING LABELS TO MERGED DATASET\")\nprint(\"=\"*60)\n\nLABELS_PATH = BASE_PATH / 'labels_rgbd'\n\nfor split in ['train', 'val', 'test']:\n    src_labels_dir = DATASET_PATH / 'labels' / split\n    dst_labels_dir = LABELS_PATH / split\n    dst_labels_dir.mkdir(parents=True, exist_ok=True)\n    \n    label_files = list(src_labels_dir.glob('*.txt'))\n    for label_file in label_files:\n        shutil.copy(str(label_file), str(dst_labels_dir / label_file.name))\n    \n    print(f\"  {split}: copied {len(label_files)} label files\")\n\n# =============================================================================\n# Verify Final Dataset Structure\n# =============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL DATASET STRUCTURE (Ready for Training)\")\nprint(\"=\"*60)\n\nfor split in ['train', 'val', 'test']:\n    imgs = len(list((MERGED_IMAGES_PATH / split).glob('*.png')))\n    lbls = len(list((LABELS_PATH / split).glob('*.txt')))\n    print(f\"  {split}: {imgs} images, {lbls} labels\")\n\n# =============================================================================\n# Setup Paths for Training\n# =============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING DATASET PATHS\")\nprint(\"=\"*60)\nprint(f\"Images root: {MERGED_IMAGES_PATH}\")\nprint(f\"Labels root: {LABELS_PATH}\")\nprint(f\"Runs output: {RUNS_PATH}\")\nprint(f\"Output directory: {KAGGLE_OUTPUT}\")\n\nprint(\"\\nSetup complete! Ready for training.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:23:42.651444Z","iopub.execute_input":"2026-01-27T10:23:42.652146Z","iopub.status.idle":"2026-01-27T10:24:40.133942Z","shell.execute_reply.started":"2026-01-27T10:23:42.652114Z","shell.execute_reply":"2026-01-27T10:24:40.133355Z"}},"outputs":[{"name":"stdout","text":"Running on: Kaggle\nDataset: /kaggle/input/ffb-localization-rgbd-dataset/ffb_localization_rgbd (exists: True)\nCUDA: True\nGPU: Tesla T4\n\n============================================================\nORIGINAL DATASET STRUCTURE\n============================================================\n  train: 280 RGB, 280 Depth, 280 labels\n  val: 80 RGB, 80 Depth, 80 labels\n  test: 40 RGB, 40 Depth, 40 labels\n\n============================================================\nMERGING RGB + DEPTH INTO 4-CHANNEL IMAGES\n============================================================\n  train: merged 280 images\n  val: merged 80 images\n  test: merged 40 images\n\n============================================================\nVERIFICATION: 4-CHANNEL MERGED IMAGES\n============================================================\n  train: 280 images, shape=(720, 1280, 4) (H√óW√óChannels)\n  val: 80 images, shape=(720, 1280, 4) (H√óW√óChannels)\n  test: 40 images, shape=(720, 1280, 4) (H√óW√óChannels)\n\n============================================================\nCOPYING LABELS TO MERGED DATASET\n============================================================\n  train: copied 280 label files\n  val: copied 80 label files\n  test: copied 40 label files\n\n============================================================\nFINAL DATASET STRUCTURE (Ready for Training)\n============================================================\n  train: 280 images, 280 labels\n  val: 80 images, 80 labels\n  test: 40 images, 40 labels\n\n============================================================\nTRAINING DATASET PATHS\n============================================================\nImages root: /kaggle/working/images_rgbd\nLabels root: /kaggle/working/labels_rgbd\nRuns output: /kaggle/working/runs/detect\nOutput directory: /kaggle/working/kaggleoutput\n\nSetup complete! Ready for training.\n","output_type":"stream"}],"execution_count":1},{"id":"yaml-cell","cell_type":"code","source":"# =============================================================================\n# Cell 2: Create YAML Configuration (FIXED - SIMPLE & CLEAN)\n# =============================================================================\n\n# Buat YAML file dengan format yang benar\nyaml_content = \"\"\"# A.3 RGB+Depth 4-Channel Dataset\npath: /kaggle/working\ntrain: images_rgbd/train\nval: images_rgbd/val\ntest: images_rgbd/test\n\nnc: 1\nnames: ['fresh_fruit_bunch']\n\"\"\"\n\nconfig_path = Path('/kaggle/working/dataset_rgbd_4ch.yaml')\n\n# Write YAML\nwith open(config_path, 'w') as f:\n    f.write(yaml_content)\n\nprint(f\"YAML Config created: {config_path}\")\nprint(f\"Exists: {config_path.exists()}\\n\")\nprint(\"=\"*60)\nprint(\"YAML CONTENT:\")\nprint(\"=\"*60)\nprint(config_path.read_text())\nprint(\"=\"*60)\n\n# Verify with YAML parser\nimport yaml\n\ntry:\n    with open(config_path, 'r') as f:\n        yaml_data = yaml.safe_load(f)\n    print(\"\\n‚úì YAML format is valid!\")\n    print(f\"\\nParsed content:\")\n    for key, value in yaml_data.items():\n        print(f\"  {key}: {value}\")\nexcept Exception as e:\n    print(f\"\\n‚úó YAML parsing error: {e}\")\n\nprint(\"\\n‚úì Ready for training!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:24:40.135149Z","iopub.execute_input":"2026-01-27T10:24:40.135494Z","iopub.status.idle":"2026-01-27T10:24:40.159052Z","shell.execute_reply.started":"2026-01-27T10:24:40.135471Z","shell.execute_reply":"2026-01-27T10:24:40.158350Z"}},"outputs":[{"name":"stdout","text":"YAML Config created: /kaggle/working/dataset_rgbd_4ch.yaml\nExists: True\n\n============================================================\nYAML CONTENT:\n============================================================\n# A.3 RGB+Depth 4-Channel Dataset\npath: /kaggle/working\ntrain: images_rgbd/train\nval: images_rgbd/val\ntest: images_rgbd/test\n\nnc: 1\nnames: ['fresh_fruit_bunch']\n\n============================================================\n\n‚úì YAML format is valid!\n\nParsed content:\n  path: /kaggle/working\n  train: images_rgbd/train\n  val: images_rgbd/val\n  test: images_rgbd/test\n  nc: 1\n  names: ['fresh_fruit_bunch']\n\n‚úì Ready for training!\n","output_type":"stream"}],"execution_count":2},{"id":"verify-yaml-cell","cell_type":"code","source":"# =============================================================================\n# Cell 3: Verify YAML (SIMPLIFIED)\n# =============================================================================\nconfig_path = Path('/kaggle/working/dataset_rgbd_4ch.yaml')\nprint(f\"YAML: {config_path}\")\nprint(config_path.read_text())\nprint(\"\\n‚úì Verification sudah dilakukan di Cell 1\")\nprint(\"‚úì Ready for training!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:24:40.160020Z","iopub.execute_input":"2026-01-27T10:24:40.160251Z","iopub.status.idle":"2026-01-27T10:24:40.164911Z","shell.execute_reply.started":"2026-01-27T10:24:40.160232Z","shell.execute_reply":"2026-01-27T10:24:40.164256Z"}},"outputs":[{"name":"stdout","text":"YAML: /kaggle/working/dataset_rgbd_4ch.yaml\n# A.3 RGB+Depth 4-Channel Dataset\npath: /kaggle/working\ntrain: images_rgbd/train\nval: images_rgbd/val\ntest: images_rgbd/test\n\nnc: 1\nnames: ['fresh_fruit_bunch']\n\n\n‚úì Verification sudah dilakukan di Cell 1\n‚úì Ready for training!\n","output_type":"stream"}],"execution_count":3},{"id":"install-cell","cell_type":"code","source":"# =============================================================================\n# Cell 4: Install Ultralytics\n# =============================================================================\n!pip install -q ultralytics\n\nfrom ultralytics import YOLO\nimport pandas as pd\nprint(\"Ultralytics ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:24:40.166319Z","iopub.execute_input":"2026-01-27T10:24:40.166526Z","iopub.status.idle":"2026-01-27T10:24:49.747256Z","shell.execute_reply.started":"2026-01-27T10:24:40.166507Z","shell.execute_reply":"2026-01-27T10:24:49.746586Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nUltralytics ready\n","output_type":"stream"}],"execution_count":4},{"id":"config-cell","cell_type":"code","source":"# =============================================================================\n# Cell 5: Training Config\n# =============================================================================\nSEEDS = [42, 123, 456, 789, 101]\nEXP_PREFIX = 'exp_a3_rgbd'\n\nprint(f\"Seeds: {SEEDS} ({len(SEEDS)} runs)\")\nprint(\"Metrics: mean ¬± std deviation\")\nprint(\"Note: Model will be modified for 4-channel input\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:24:49.748200Z","iopub.execute_input":"2026-01-27T10:24:49.748551Z","iopub.status.idle":"2026-01-27T10:24:49.753103Z","shell.execute_reply.started":"2026-01-27T10:24:49.748521Z","shell.execute_reply":"2026-01-27T10:24:49.752429Z"}},"outputs":[{"name":"stdout","text":"Seeds: [42, 123, 456, 789, 101] (5 runs)\nMetrics: mean ¬± std deviation\nNote: Model will be modified for 4-channel input\n","output_type":"stream"}],"execution_count":5},{"id":"e022bae7-451e-4a81-8190-4693c58b21fa","cell_type":"code","source":"# =============================================================================\n# FIXED: Helper Function untuk Modify YOLO Model untuk 4-Channel Input\n# =============================================================================\n\nimport torch\nfrom ultralytics import YOLO\n\ndef modify_yolo_for_4ch(model_path='yolo11n.pt'):\n    \"\"\"\n    Modify YOLOv11n untuk accept 4-channel input (RGBD)\n    \n    Default YOLO expects 3-channel (RGB) input.\n    Fungsi ini memodifikasi first convolutional layer untuk accept 4 channels.\n    \n    Args:\n        model_path: Path ke YOLO model weights\n    \n    Returns:\n        Modified YOLO model ready untuk 4-channel input\n    \"\"\"\n    print(\"Loading YOLO model...\")\n    model = YOLO(model_path)\n    \n    # DEBUG: Print model structure untuk understand\n    print(\"\\nModel structure exploration:\")\n    print(f\"Type of model.model: {type(model.model)}\")\n    print(f\"Type of model.model.model: {type(model.model.model)}\")\n    print(f\"Length of model.model.model: {len(model.model.model)}\")\n    \n    # Get first layer (should be Detect or Conv)\n    first_layer = model.model.model[0]\n    print(f\"First layer type: {type(first_layer)}\")\n    print(f\"First layer: {first_layer}\")\n    \n    # Iterate untuk find first Conv layer\n    first_conv = None\n    for i, layer in enumerate(model.model.model):\n        print(f\"\\nLayer {i}: {type(layer).__name__}\")\n        if hasattr(layer, 'conv'):\n            first_conv = layer.conv\n            print(f\"  Found conv at layer {i}\")\n            break\n        elif hasattr(layer, 'convs'):  # Multiple convs\n            first_conv = layer.convs[0] if isinstance(layer.convs, (list, tuple)) else layer.convs\n            print(f\"  Found convs at layer {i}\")\n            break\n    \n    if first_conv is None:\n        # Fallback: Try to get first Conv dari model\n        print(\"\\nFallback: Searching dalam model.modules()...\")\n        for module in model.model.modules():\n            if isinstance(module, torch.nn.Conv2d):\n                first_conv = module\n                print(f\"  Found Conv2d: in_channels={module.in_channels}, out_channels={module.out_channels}\")\n                break\n    \n    if first_conv is None:\n        raise RuntimeError(\"Could not find Conv2d layer in model!\")\n    \n    print(f\"\\n{'='*60}\")\n    print(\"MODIFYING CONV LAYER FOR 4-CHANNEL INPUT\")\n    print(f\"{'='*60}\")\n    print(f\"Original in_channels: {first_conv.in_channels}\")\n    print(f\"Original weight shape: {first_conv.weight.shape}\")\n    print(f\"  [out_channels={first_conv.weight.shape[0]}, in_channels={first_conv.weight.shape[1]}, kernel_h={first_conv.weight.shape[2]}, kernel_w={first_conv.weight.shape[3]}]\")\n    \n    # Modifikasi in_channels dari 3 ke 4\n    first_conv.in_channels = 4\n    \n    # Modifikasi weight tensor\n    # Original: [out_channels, 3, kernel_h, kernel_w]\n    # Target: [out_channels, 4, kernel_h, kernel_w]\n    \n    original_weight = first_conv.weight.data\n    \n    # Replicate first channel untuk Depth initialization\n    # Ini adalah reasonable initialization karena depth channel akan di-learn\n    new_weight = torch.cat([\n        original_weight,\n        original_weight[:, :1, :, :]  # Replicate first channel (Blue) untuk Depth\n    ], dim=1)\n    \n    first_conv.weight = torch.nn.Parameter(new_weight)\n    \n    print(f\"\\nModified in_channels: {first_conv.in_channels}\")\n    print(f\"Modified weight shape: {first_conv.weight.shape}\")\n    print(f\"  [out_channels={first_conv.weight.shape[0]}, in_channels={first_conv.weight.shape[1]}, kernel_h={first_conv.weight.shape[2]}, kernel_w={first_conv.weight.shape[3]}]\")\n    print(f\"\\n‚úì Model successfully modified untuk 4-channel input!\")\n    \n    return model\n\n# =============================================================================\n# TEST: Verify modification berhasil\n# =============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTING MODEL MODIFICATION\")\nprint(\"=\"*60)\n\ntry:\n    test_model = modify_yolo_for_4ch('yolo11n.pt')\n    print(\"\\n‚úì Model modification successful!\")\nexcept Exception as e:\n    print(f\"\\n‚úó Error during modification: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:24:49.753975Z","iopub.execute_input":"2026-01-27T10:24:49.754246Z","iopub.status.idle":"2026-01-27T10:24:50.118754Z","shell.execute_reply.started":"2026-01-27T10:24:49.754221Z","shell.execute_reply":"2026-01-27T10:24:50.118019Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTESTING MODEL MODIFICATION\n============================================================\nLoading YOLO model...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 120.9MB/s 0.0s\n\nModel structure exploration:\nType of model.model: <class 'ultralytics.nn.tasks.DetectionModel'>\nType of model.model.model: <class 'torch.nn.modules.container.Sequential'>\nLength of model.model.model: 24\nFirst layer type: <class 'ultralytics.nn.modules.conv.Conv'>\nFirst layer: Conv(\n  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n  (act): SiLU(inplace=True)\n)\n\nLayer 0: Conv\n  Found conv at layer 0\n\n============================================================\nMODIFYING CONV LAYER FOR 4-CHANNEL INPUT\n============================================================\nOriginal in_channels: 3\nOriginal weight shape: torch.Size([16, 3, 3, 3])\n  [out_channels=16, in_channels=3, kernel_h=3, kernel_w=3]\n\nModified in_channels: 4\nModified weight shape: torch.Size([16, 4, 3, 3])\n  [out_channels=16, in_channels=4, kernel_h=3, kernel_w=3]\n\n‚úì Model successfully modified untuk 4-channel input!\n\n‚úì Model modification successful!\n","output_type":"stream"}],"execution_count":6},{"id":"d65929d7-0bda-4b12-a5aa-26239c54f208","cell_type":"code","source":"# =============================================================================\n# NEW CELL: Fix Dataset Structure (Insert sebelum Cell 6)\n# =============================================================================\n# Jalankan ini SEBELUM training untuk fix label issue\n\nimport os\nfrom pathlib import Path\n\nprint(\"=\"*60)\nprint(\"FIXING DATASET STRUCTURE FOR YOLO\")\nprint(\"=\"*60)\n\nBASE_PATH = Path('/kaggle/working')\n\n# Create standard structure\nIMAGES_PATH = BASE_PATH / 'images'\nLABELS_PATH = BASE_PATH / 'labels'\n\nprint(f\"\\nCreating directory structure...\")\nIMAGES_PATH.mkdir(exist_ok=True)\nLABELS_PATH.mkdir(exist_ok=True)\n\n# Create symlinks untuk images dan labels\nprint(\"\\nCreating symlinks...\")\nfor split in ['train', 'val', 'test']:\n    # Images\n    src_img = BASE_PATH / 'images_rgbd' / split\n    dst_img = IMAGES_PATH / split\n    \n    if src_img.exists():\n        if dst_img.exists():\n            if dst_img.is_symlink():\n                os.unlink(dst_img)\n            else:\n                import shutil\n                shutil.rmtree(dst_img)\n        \n        os.symlink(src_img, dst_img)\n        print(f\"  ‚úì {dst_img.name} -> {src_img.name}\")\n    \n    # Labels\n    src_lbl = BASE_PATH / 'labels_rgbd' / split\n    dst_lbl = LABELS_PATH / split\n    \n    if src_lbl.exists():\n        if dst_lbl.exists():\n            if dst_lbl.is_symlink():\n                os.unlink(dst_lbl)\n            else:\n                import shutil\n                shutil.rmtree(dst_lbl)\n        \n        os.symlink(src_lbl, dst_lbl)\n        print(f\"  ‚úì {dst_lbl.name} -> {src_lbl.name}\")\n\n# Update YAML dengan path yang benar\nprint(\"\\nUpdating YAML configuration...\")\n\nyaml_content = \"\"\"path: /kaggle/working\ntrain: images/train\nval: images/val\ntest: images/test\n\nnc: 1\nnames: ['fresh_fruit_bunch']\n\"\"\"\n\nconfig_path = Path('/kaggle/working/dataset_rgbd_4ch.yaml')\nwith open(config_path, 'w') as f:\n    f.write(yaml_content)\n\nprint(f\"‚úì Updated: {config_path}\")\n\n# Verify structure\nprint(\"\\n\" + \"=\"*60)\nprint(\"VERIFICATION\")\nprint(\"=\"*60)\n\nprint(\"\\nDirectory structure:\")\nprint(f\"  {IMAGES_PATH}:\")\nfor split in ['train', 'val', 'test']:\n    path = IMAGES_PATH / split\n    if path.exists():\n        count = len(list(path.glob('*.png')))\n        print(f\"    {split}: {count} images\")\n\nprint(f\"\\n  {LABELS_PATH}:\")\nfor split in ['train', 'val', 'test']:\n    path = LABELS_PATH / split\n    if path.exists():\n        count = len(list(path.glob('*.txt')))\n        print(f\"    {split}: {count} labels\")\n\nprint(f\"\\nYAML content:\")\nprint(config_path.read_text())\n\nprint(\"=\"*60)\nprint(\"‚úì Dataset structure is now YOLO-compatible!\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:24:50.119747Z","iopub.execute_input":"2026-01-27T10:24:50.120069Z","iopub.status.idle":"2026-01-27T10:24:50.134513Z","shell.execute_reply.started":"2026-01-27T10:24:50.120037Z","shell.execute_reply":"2026-01-27T10:24:50.133948Z"}},"outputs":[{"name":"stdout","text":"============================================================\nFIXING DATASET STRUCTURE FOR YOLO\n============================================================\n\nCreating directory structure...\n\nCreating symlinks...\n  ‚úì train -> train\n  ‚úì train -> train\n  ‚úì val -> val\n  ‚úì val -> val\n  ‚úì test -> test\n  ‚úì test -> test\n\nUpdating YAML configuration...\n‚úì Updated: /kaggle/working/dataset_rgbd_4ch.yaml\n\n============================================================\nVERIFICATION\n============================================================\n\nDirectory structure:\n  /kaggle/working/images:\n    train: 280 images\n    val: 80 images\n    test: 40 images\n\n  /kaggle/working/labels:\n    train: 280 labels\n    val: 80 labels\n    test: 40 labels\n\nYAML content:\npath: /kaggle/working\ntrain: images/train\nval: images/val\ntest: images/test\n\nnc: 1\nnames: ['fresh_fruit_bunch']\n\n============================================================\n‚úì Dataset structure is now YOLO-compatible!\n============================================================\n","output_type":"stream"}],"execution_count":7},{"id":"training-cell","cell_type":"code","source":"# =============================================================================\n# Cell 6: Training Loop (4-Channel RGBD) - FIXED\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING A.3 (4-CHANNEL RGBD)\")\nprint(\"=\"*60)\n\nfor seed in SEEDS:\n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING A.3 RGBD (4-CH) - Seed {seed} ({SEEDS.index(seed)+1}/{len(SEEDS)})\")\n    print(f\"{'='*60}\\n\")\n    \n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    \n    # Load dan modify model untuk 4-channel input\n    model = modify_yolo_for_4ch('yolo11n.pt')\n    \n    results = model.train(\n        data=str(config_path),  # config_path dari Cell 2\n        epochs=1,  # PENTING: Change dari 1 ke 100 untuk production!\n        patience=30,\n        seed=seed,\n        name=f\"{EXP_PREFIX}_seed{seed}\",\n        exist_ok=True,\n        imgsz=640,  # Resize ke 640 (dari 720)\n    )\n    \n    print(f\"\\nSeed {seed} complete!\")\n    print(f\"mAP50: {results.results_dict.get('metrics/mAP50(B)', 0):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:24:50.135394Z","iopub.execute_input":"2026-01-27T10:24:50.135685Z","iopub.status.idle":"2026-01-27T10:27:10.738492Z","shell.execute_reply.started":"2026-01-27T10:24:50.135663Z","shell.execute_reply":"2026-01-27T10:27:10.737578Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTARTING TRAINING A.3 (4-CHANNEL RGBD)\n============================================================\n\n============================================================\nTRAINING A.3 RGBD (4-CH) - Seed 42 (1/5)\n============================================================\n\nLoading YOLO model...\n\nModel structure exploration:\nType of model.model: <class 'ultralytics.nn.tasks.DetectionModel'>\nType of model.model.model: <class 'torch.nn.modules.container.Sequential'>\nLength of model.model.model: 24\nFirst layer type: <class 'ultralytics.nn.modules.conv.Conv'>\nFirst layer: Conv(\n  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n  (act): SiLU(inplace=True)\n)\n\nLayer 0: Conv\n  Found conv at layer 0\n\n============================================================\nMODIFYING CONV LAYER FOR 4-CHANNEL INPUT\n============================================================\nOriginal in_channels: 3\nOriginal weight shape: torch.Size([16, 3, 3, 3])\n  [out_channels=16, in_channels=3, kernel_h=3, kernel_w=3]\n\nModified in_channels: 4\nModified weight shape: torch.Size([16, 4, 3, 3])\n  [out_channels=16, in_channels=4, kernel_h=3, kernel_w=3]\n\n‚úì Model successfully modified untuk 4-channel input!\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset_rgbd_4ch.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=exp_a3_rgbd_seed42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/exp_a3_rgbd_seed42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 25.7MB/s 0.0s\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, 16, None, [64, 128, 256]] \nYOLO11n summary: 182 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n\nTransferred 448/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 90.9MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4676.8¬±1009.6 MB/s, size: 2076.3 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/images_rgbd/train... 0 images, 280 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 280/280 85.8it/s 3.3s0.1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in /kaggle/working/images_rgbd/train.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/images_rgbd/train.cache\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2118.6¬±1568.8 MB/s, size: 2329.4 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/val... 0 images, 80 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 87.6it/s 0.9s0.1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mNo labels found in /kaggle/working/images_rgbd/val.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/images_rgbd/val.cache\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\nPlotting labels to /kaggle/working/runs/detect/exp_a3_rgbd_seed42/labels.jpg... \nWARNING ‚ö†Ô∏è zero-size array to reduction operation maximum which has no identity\n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed42\u001b[0m\nStarting training for 1 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K        1/1      2.18G          0      131.1          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18/18 1.3s/it 23.3s0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.0s/it 5.9s0.6ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n\n1 epochs completed in 0.009 hours.\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed42/weights/last.pt, 5.4MB\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed42/weights/best.pt, 5.4MB\n\nValidating /kaggle/working/runs/detect/exp_a3_rgbd_seed42/weights/best.pt...\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.0it/s 0.6s0.3s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 0.1ms preprocess, 2.4ms inference, 0.0ms loss, 3.1ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed42\u001b[0m\n\nSeed 42 complete!\nmAP50: 0.000\n\n============================================================\nTRAINING A.3 RGBD (4-CH) - Seed 123 (2/5)\n============================================================\n\nLoading YOLO model...\n\nModel structure exploration:\nType of model.model: <class 'ultralytics.nn.tasks.DetectionModel'>\nType of model.model.model: <class 'torch.nn.modules.container.Sequential'>\nLength of model.model.model: 24\nFirst layer type: <class 'ultralytics.nn.modules.conv.Conv'>\nFirst layer: Conv(\n  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n  (act): SiLU(inplace=True)\n)\n\nLayer 0: Conv\n  Found conv at layer 0\n\n============================================================\nMODIFYING CONV LAYER FOR 4-CHANNEL INPUT\n============================================================\nOriginal in_channels: 3\nOriginal weight shape: torch.Size([16, 3, 3, 3])\n  [out_channels=16, in_channels=3, kernel_h=3, kernel_w=3]\n\nModified in_channels: 4\nModified weight shape: torch.Size([16, 4, 3, 3])\n  [out_channels=16, in_channels=4, kernel_h=3, kernel_w=3]\n\n‚úì Model successfully modified untuk 4-channel input!\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset_rgbd_4ch.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=exp_a3_rgbd_seed123, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/exp_a3_rgbd_seed123, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=123, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, 16, None, [64, 128, 256]] \nYOLO11n summary: 182 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n\nTransferred 448/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4457.3¬±860.7 MB/s, size: 2177.4 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/images_rgbd/train.cache... 0 images, 280 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 280/280 130.5Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3503.3¬±2365.5 MB/s, size: 2331.5 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/val.cache... 0 images, 80 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 7.5Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\nPlotting labels to /kaggle/working/runs/detect/exp_a3_rgbd_seed123/labels.jpg... \nWARNING ‚ö†Ô∏è zero-size array to reduction operation maximum which has no identity\n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed123\u001b[0m\nStarting training for 1 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K        1/1      2.15G          0      111.8          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18/18 1.9it/s 9.3s0.8s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.3it/s 0.7s0.3s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n\n1 epochs completed in 0.004 hours.\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed123/weights/last.pt, 5.4MB\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed123/weights/best.pt, 5.4MB\n\nValidating /kaggle/working/runs/detect/exp_a3_rgbd_seed123/weights/best.pt...\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.0it/s 0.6s0.3s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 2.5ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed123\u001b[0m\n\nSeed 123 complete!\nmAP50: 0.000\n\n============================================================\nTRAINING A.3 RGBD (4-CH) - Seed 456 (3/5)\n============================================================\n\nLoading YOLO model...\n\nModel structure exploration:\nType of model.model: <class 'ultralytics.nn.tasks.DetectionModel'>\nType of model.model.model: <class 'torch.nn.modules.container.Sequential'>\nLength of model.model.model: 24\nFirst layer type: <class 'ultralytics.nn.modules.conv.Conv'>\nFirst layer: Conv(\n  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n  (act): SiLU(inplace=True)\n)\n\nLayer 0: Conv\n  Found conv at layer 0\n\n============================================================\nMODIFYING CONV LAYER FOR 4-CHANNEL INPUT\n============================================================\nOriginal in_channels: 3\nOriginal weight shape: torch.Size([16, 3, 3, 3])\n  [out_channels=16, in_channels=3, kernel_h=3, kernel_w=3]\n\nModified in_channels: 4\nModified weight shape: torch.Size([16, 4, 3, 3])\n  [out_channels=16, in_channels=4, kernel_h=3, kernel_w=3]\n\n‚úì Model successfully modified untuk 4-channel input!\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset_rgbd_4ch.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=exp_a3_rgbd_seed456, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/exp_a3_rgbd_seed456, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=456, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, 16, None, [64, 128, 256]] \nYOLO11n summary: 182 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n\nTransferred 448/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5927.8¬±1055.5 MB/s, size: 2265.2 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/images_rgbd/train.cache... 0 images, 280 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 280/280 130.5Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1829.8¬±1800.2 MB/s, size: 2232.1 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/val.cache... 0 images, 80 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 6.1Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\nPlotting labels to /kaggle/working/runs/detect/exp_a3_rgbd_seed456/labels.jpg... \nWARNING ‚ö†Ô∏è zero-size array to reduction operation maximum which has no identity\n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed456\u001b[0m\nStarting training for 1 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K        1/1      2.17G          0        124          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18/18 1.9it/s 9.3s0.8s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.0it/s 0.6s0.3s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n\n1 epochs completed in 0.004 hours.\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed456/weights/last.pt, 5.4MB\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed456/weights/best.pt, 5.4MB\n\nValidating /kaggle/working/runs/detect/exp_a3_rgbd_seed456/weights/best.pt...\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.7it/s 0.5s0.3s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 3.0ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed456\u001b[0m\n\nSeed 456 complete!\nmAP50: 0.000\n\n============================================================\nTRAINING A.3 RGBD (4-CH) - Seed 789 (4/5)\n============================================================\n\nLoading YOLO model...\n\nModel structure exploration:\nType of model.model: <class 'ultralytics.nn.tasks.DetectionModel'>\nType of model.model.model: <class 'torch.nn.modules.container.Sequential'>\nLength of model.model.model: 24\nFirst layer type: <class 'ultralytics.nn.modules.conv.Conv'>\nFirst layer: Conv(\n  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n  (act): SiLU(inplace=True)\n)\n\nLayer 0: Conv\n  Found conv at layer 0\n\n============================================================\nMODIFYING CONV LAYER FOR 4-CHANNEL INPUT\n============================================================\nOriginal in_channels: 3\nOriginal weight shape: torch.Size([16, 3, 3, 3])\n  [out_channels=16, in_channels=3, kernel_h=3, kernel_w=3]\n\nModified in_channels: 4\nModified weight shape: torch.Size([16, 4, 3, 3])\n  [out_channels=16, in_channels=4, kernel_h=3, kernel_w=3]\n\n‚úì Model successfully modified untuk 4-channel input!\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset_rgbd_4ch.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=exp_a3_rgbd_seed789, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/exp_a3_rgbd_seed789, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=789, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, 16, None, [64, 128, 256]] \nYOLO11n summary: 182 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n\nTransferred 448/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4435.8¬±900.2 MB/s, size: 2253.4 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/images_rgbd/train.cache... 0 images, 280 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 280/280 117.4Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2879.3¬±2018.7 MB/s, size: 2181.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/val.cache... 0 images, 80 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 7.3Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\nPlotting labels to /kaggle/working/runs/detect/exp_a3_rgbd_seed789/labels.jpg... \nWARNING ‚ö†Ô∏è zero-size array to reduction operation maximum which has no identity\n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed789\u001b[0m\nStarting training for 1 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K        1/1      2.17G          0      123.2          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18/18 2.0it/s 9.2s0.8s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.8it/s 0.8s0.4s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n\n1 epochs completed in 0.004 hours.\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed789/weights/last.pt, 5.4MB\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed789/weights/best.pt, 5.4MB\n\nValidating /kaggle/working/runs/detect/exp_a3_rgbd_seed789/weights/best.pt...\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.6it/s 0.7s0.3s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 0.1ms preprocess, 2.6ms inference, 0.0ms loss, 3.2ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed789\u001b[0m\n\nSeed 789 complete!\nmAP50: 0.000\n\n============================================================\nTRAINING A.3 RGBD (4-CH) - Seed 101 (5/5)\n============================================================\n\nLoading YOLO model...\n\nModel structure exploration:\nType of model.model: <class 'ultralytics.nn.tasks.DetectionModel'>\nType of model.model.model: <class 'torch.nn.modules.container.Sequential'>\nLength of model.model.model: 24\nFirst layer type: <class 'ultralytics.nn.modules.conv.Conv'>\nFirst layer: Conv(\n  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n  (act): SiLU(inplace=True)\n)\n\nLayer 0: Conv\n  Found conv at layer 0\n\n============================================================\nMODIFYING CONV LAYER FOR 4-CHANNEL INPUT\n============================================================\nOriginal in_channels: 3\nOriginal weight shape: torch.Size([16, 3, 3, 3])\n  [out_channels=16, in_channels=3, kernel_h=3, kernel_w=3]\n\nModified in_channels: 4\nModified weight shape: torch.Size([16, 4, 3, 3])\n  [out_channels=16, in_channels=4, kernel_h=3, kernel_w=3]\n\n‚úì Model successfully modified untuk 4-channel input!\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset_rgbd_4ch.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=exp_a3_rgbd_seed101, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/exp_a3_rgbd_seed101, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=101, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, 16, None, [64, 128, 256]] \nYOLO11n summary: 182 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n\nTransferred 448/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5894.2¬±1273.7 MB/s, size: 2194.4 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/images_rgbd/train.cache... 0 images, 280 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 280/280 117.4Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1868.5¬±1646.6 MB/s, size: 2251.3 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/val.cache... 0 images, 80 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80/80 5.0Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\nPlotting labels to /kaggle/working/runs/detect/exp_a3_rgbd_seed101/labels.jpg... \nWARNING ‚ö†Ô∏è zero-size array to reduction operation maximum which has no identity\n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed101\u001b[0m\nStarting training for 1 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K        1/1      2.17G          0      117.7          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18/18 2.0it/s 9.2s0.8s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.3it/s 0.9s0.5s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n\n1 epochs completed in 0.004 hours.\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed101/weights/last.pt, 5.4MB\nOptimizer stripped from /kaggle/working/runs/detect/exp_a3_rgbd_seed101/weights/best.pt, 5.4MB\n\nValidating /kaggle/working/runs/detect/exp_a3_rgbd_seed101/weights/best.pt...\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.5it/s 0.5s0.3s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         80          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 2.6ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/exp_a3_rgbd_seed101\u001b[0m\n\nSeed 101 complete!\nmAP50: 0.000\n","output_type":"stream"}],"execution_count":8},{"id":"eval-cell","cell_type":"code","source":"# =============================================================================\n# Cell 7: Evaluation on Test Set\n# =============================================================================\nresults_dict = {}\n\nprint(\"=\"*60)\nprint(\"EVALUATION ON TEST SET\")\nprint(\"=\"*60)\n\nfor seed in SEEDS:\n    model_path = RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / 'weights' / 'best.pt'\n    \n    if not model_path.exists():\n        print(f\"Not found: {model_path}\")\n        continue\n    \n    print(f\"\\nSeed {seed}:\")\n    model = YOLO(str(model_path))\n    metrics = model.val(data=str(config_path), split='test')\n    \n    results_dict[seed] = {\n        'mAP50': metrics.box.map50,\n        'mAP50-95': metrics.box.map,\n        'Precision': metrics.box.mp,\n        'Recall': metrics.box.mr\n    }\n    \n    print(f\"  mAP50: {metrics.box.map50:.3f}\")\n    print(f\"  mAP50-95: {metrics.box.map:.3f}\")\n    print(f\"  Precision: {metrics.box.mp:.3f}\")\n    print(f\"  Recall: {metrics.box.mr:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:27:10.739853Z","iopub.execute_input":"2026-01-27T10:27:10.740424Z","iopub.status.idle":"2026-01-27T10:27:31.635962Z","shell.execute_reply.started":"2026-01-27T10:27:10.740383Z","shell.execute_reply":"2026-01-27T10:27:31.635283Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEVALUATION ON TEST SET\n============================================================\n\nSeed 42:\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3883.0¬±1620.0 MB/s, size: 2217.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/test... 0 images, 40 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40/40 86.8it/s 0.5s0.1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mNo labels found in /kaggle/working/images_rgbd/test.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/images_rgbd/test.cache\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/test.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.5it/s 1.2s0.7s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         40          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 3.7ms preprocess, 8.0ms inference, 0.0ms loss, 1.5ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val\u001b[0m\n  mAP50: 0.000\n  mAP50-95: 0.000\n  Precision: 0.000\n  Recall: 0.000\n\nSeed 123:\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4096.4¬±1190.5 MB/s, size: 2250.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/test.cache... 0 images, 40 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40/40 18.6Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/test.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.5it/s 1.2s0.6s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         40          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 2.0ms preprocess, 5.3ms inference, 0.0ms loss, 2.8ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val2\u001b[0m\n  mAP50: 0.000\n  mAP50-95: 0.000\n  Precision: 0.000\n  Recall: 0.000\n\nSeed 456:\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5004.2¬±996.9 MB/s, size: 2183.9 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/test.cache... 0 images, 40 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40/40 16.8Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/test.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.5it/s 1.2s0.7s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         40          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 3.4ms preprocess, 3.3ms inference, 0.0ms loss, 1.7ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val3\u001b[0m\n  mAP50: 0.000\n  mAP50-95: 0.000\n  Precision: 0.000\n  Recall: 0.000\n\nSeed 789:\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5373.6¬±1304.2 MB/s, size: 2297.8 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/test.cache... 0 images, 40 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40/40 21.0Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/test.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.6it/s 1.2s0.6s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         40          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 3.5ms preprocess, 3.5ms inference, 0.0ms loss, 1.8ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val4\u001b[0m\n  mAP50: 0.000\n  mAP50-95: 0.000\n  Precision: 0.000\n  Recall: 0.000\n\nSeed 101:\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11n summary (fused): 101 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4490.9¬±1009.2 MB/s, size: 2288.2 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/images_rgbd/test.cache... 0 images, 40 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40/40 15.3Mit/s 0.0s\nWARNING ‚ö†Ô∏è Labels are missing or empty in /kaggle/working/images_rgbd/test.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.6it/s 1.1s0.7s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:655: RuntimeWarning: Mean of empty slice.\n  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:701: RuntimeWarning: Mean of empty slice.\n  y = smooth(py.mean(0), 0.1)\n/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:837: RuntimeWarning: Mean of empty slice.\n  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","output_type":"stream"},{"name":"stdout","text":"                   all         40          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\nSpeed: 3.2ms preprocess, 4.1ms inference, 0.0ms loss, 2.7ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val5\u001b[0m\n  mAP50: 0.000\n  mAP50-95: 0.000\n  Precision: 0.000\n  Recall: 0.000\n","output_type":"stream"}],"execution_count":9},{"id":"results-cell","cell_type":"code","source":"# =============================================================================\n# Cell 8: Results Summary\n# =============================================================================\ndf = pd.DataFrame(results_dict).T\ndf.index.name = 'Seed'\n\n# Calculate mean and std\navg = df.mean()\nstd = df.std()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"A.3 RGB+DEPTH (REAL) - FINAL RESULTS\")\nprint(\"=\"*60 + \"\\n\")\nprint(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"SUMMARY (Mean ¬± Std)\")\nprint(\"-\"*60)\nfor col in df.columns:\n    print(f\"  {col}: {avg[col]:.3f} ¬± {std[col]:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:27:31.638802Z","iopub.execute_input":"2026-01-27T10:27:31.639110Z","iopub.status.idle":"2026-01-27T10:27:31.661531Z","shell.execute_reply.started":"2026-01-27T10:27:31.639078Z","shell.execute_reply":"2026-01-27T10:27:31.660764Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nA.3 RGB+DEPTH (REAL) - FINAL RESULTS\n============================================================\n\n      mAP50  mAP50-95  Precision  Recall\nSeed                                    \n42    0.000     0.000      0.000   0.000\n123   0.000     0.000      0.000   0.000\n456   0.000     0.000      0.000   0.000\n789   0.000     0.000      0.000   0.000\n101   0.000     0.000      0.000   0.000\n\n------------------------------------------------------------\nSUMMARY (Mean ¬± Std)\n------------------------------------------------------------\n  mAP50: 0.000 ¬± 0.000\n  mAP50-95: 0.000 ¬± 0.000\n  Precision: 0.000 ¬± 0.000\n  Recall: 0.000 ¬± 0.000\n","output_type":"stream"}],"execution_count":10},{"id":"save-cell","cell_type":"code","source":"# =============================================================================\n# Cell 9: Save Results\n# =============================================================================\noutput_file = KAGGLE_OUTPUT / 'a3_rgbd_results.txt'\n\nwith open(output_file, 'w') as f:\n    f.write(\"=\"*60 + \"\\n\")\n    f.write(\"A.3 RGB+Depth (Real) 4-Channel Results\\n\")\n    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    f.write(\"Training: epochs=100, patience=30, other=default\\n\")\n    f.write(f\"Seeds: {SEEDS}\\n\")\n    f.write(\"=\"*60 + \"\\n\\n\")\n    f.write(\"Per-Seed Results:\\n\")\n    f.write(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n    f.write(\"\\n\\n\" + \"-\"*60 + \"\\n\")\n    f.write(\"Summary (Mean ¬± Std):\\n\")\n    for col in df.columns:\n        f.write(f\"  {col}: {avg[col]:.3f} ¬± {std[col]:.3f}\\n\")\n\nprint(f\"Results saved: {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:27:31.662472Z","iopub.execute_input":"2026-01-27T10:27:31.662867Z","iopub.status.idle":"2026-01-27T10:27:31.670390Z","shell.execute_reply.started":"2026-01-27T10:27:31.662842Z","shell.execute_reply":"2026-01-27T10:27:31.669804Z"}},"outputs":[{"name":"stdout","text":"Results saved: /kaggle/working/kaggleoutput/a3_rgbd_results.txt\n","output_type":"stream"}],"execution_count":11},{"id":"archive-cell","cell_type":"code","source":"# =============================================================================\n# Cell 10: Create Archives\n# =============================================================================\nif RUNS_PATH.exists():\n    shutil.make_archive('/kaggle/working/a3_runs', 'zip', RUNS_PATH)\n    print(f\"a3_runs.zip: {os.path.getsize('/kaggle/working/a3_runs.zip')/1024/1024:.1f} MB\")\n\nshutil.make_archive('/kaggle/working/a3_output', 'zip', KAGGLE_OUTPUT)\nprint(\"a3_output.zip created\")\n\nprint(\"\\nDownload from Output tab\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T10:27:31.671205Z","iopub.execute_input":"2026-01-27T10:27:31.671525Z","iopub.status.idle":"2026-01-27T10:27:36.287955Z","shell.execute_reply.started":"2026-01-27T10:27:31.671483Z","shell.execute_reply":"2026-01-27T10:27:36.287222Z"}},"outputs":[{"name":"stdout","text":"a3_runs.zip: 97.4 MB\na3_output.zip created\n\nDownload from Output tab\n","output_type":"stream"}],"execution_count":12}]}