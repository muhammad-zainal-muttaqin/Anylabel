{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.3 - RGB+Depth (Real) 4-Channel Training - FIXED\n",
    "\n",
    "**Experiment:** A.3  \n",
    "**Input:** RGB+Depth (4-channel RGBD)  \n",
    "**Objective:** Test fusion of RGB and real depth data  \n",
    "**Classes:** 1 (fresh_fruit_bunch)\n",
    "\n",
    "## Fix Applied\n",
    "- Custom RGBD Dataset loader (load RGB + Depth, stack to 4-channel)\n",
    "- Custom Trainer & Validator with 4-channel support\n",
    "- Model architecture modification (first conv layer: 3→4 channels)\n",
    "- Synchronized dataset structure validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics\n",
    "!pip install -q ultralytics\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.data.dataset import YOLODataset\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer, DetectionValidator\n",
    "\n",
    "# Disable WANDB\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Detect environment\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Dataset Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths configuration\n",
    "if IS_KAGGLE:\n",
    "    DATASET_DIR = Path(\"/kaggle/input/ffb-localization-rgbd-dataset/ffb_localization_rgbd\")\n",
    "    WORK_DIR = Path(\"/kaggle/working/ffb_localization_rgbd\")\n",
    "    BASE_PATH = Path(\"/kaggle/working\")\n",
    "else:\n",
    "    # Local paths - adjust as needed\n",
    "    BASE_PATH = Path(r\"D:/Work/Assisten Dosen/Anylabel/Experiments\")\n",
    "    DATASET_DIR = BASE_PATH / \"datasets\" / \"ffb_localization_rgbd\"\n",
    "    WORK_DIR = BASE_PATH / \"working\" / \"ffb_localization_rgbd\"\n",
    "\n",
    "RUNS_PATH = BASE_PATH / 'runs' / 'detect'\n",
    "KAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\n",
    "KAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset Dir: {DATASET_DIR}\")\n",
    "print(f\"Work Dir: {WORK_DIR}\")\n",
    "\n",
    "# Verify dataset structure\n",
    "for folder in ['rgb', 'depth', 'labels']:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        path = DATASET_DIR / folder / split\n",
    "        if path.exists():\n",
    "            count = len(list(path.glob('*.png' if folder != 'labels' else '*.txt')))\n",
    "            print(f\"  {folder}/{split}: {count} files\")\n",
    "        else:\n",
    "            print(f\"  ⚠️ Missing: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Sync Dataset & Create Images Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync RGBD dataset - keep only paired files\n",
    "def sync_rgbd_dataset(root: Path, work_root: Path) -> None:\n",
    "    \"\"\"Sync RGB and Depth dataset, keeping only paired files\"\"\"\n",
    "    splits = (\"train\", \"val\", \"test\")\n",
    "    \n",
    "    for split in splits:\n",
    "        rgb_dir = root / \"rgb\" / split\n",
    "        depth_dir = root / \"depth\" / split\n",
    "        label_dir = root / \"labels\" / split\n",
    "        \n",
    "        # Check existence\n",
    "        if not all([rgb_dir.exists(), depth_dir.exists(), label_dir.exists()]):\n",
    "            print(f\"⚠️ Missing folders for {split}\")\n",
    "            continue\n",
    "        \n",
    "        rgb_files = {p.name for p in rgb_dir.glob(\"*.png\")}\n",
    "        depth_files = {p.name for p in depth_dir.glob(\"*.png\")}\n",
    "        label_files = {p.with_suffix(\".png\").name for p in label_dir.glob(\"*.txt\")}\n",
    "        \n",
    "        # Find common files\n",
    "        keep = rgb_files & depth_files & label_files\n",
    "        \n",
    "        print(f\"{split}: RGB={len(rgb_files)}, Depth={len(depth_files)}, Labels={len(label_files)} -> Keep={len(keep)}\")\n",
    "        \n",
    "        # Create images folder (symlink/copy RGB for Ultralytics)\n",
    "        images_dir = work_root / \"images\" / split\n",
    "        images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        labels_out_dir = work_root / \"labels\" / split\n",
    "        labels_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy valid files\n",
    "        for fname in keep:\n",
    "            # Copy RGB to images\n",
    "            src_rgb = rgb_dir / fname\n",
    "            dst_rgb = images_dir / fname\n",
    "            if not dst_rgb.exists():\n",
    "                shutil.copy2(src_rgb, dst_rgb)\n",
    "            \n",
    "            # Copy depth\n",
    "            src_depth = depth_dir / fname\n",
    "            dst_depth = work_root / \"depth\" / split / fname\n",
    "            dst_depth.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if not dst_depth.exists():\n",
    "                shutil.copy2(src_depth, dst_depth)\n",
    "            \n",
    "            # Copy label\n",
    "            src_label = label_dir / fname.replace(\".png\", \".txt\")\n",
    "            dst_label = labels_out_dir / fname.replace(\".png\", \".txt\")\n",
    "            if not dst_label.exists():\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "\n",
    "# Run sync\n",
    "sync_rgbd_dataset(DATASET_DIR, WORK_DIR)\n",
    "print(f\"\\n✓ Dataset synced to: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Create YAML Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YAML config\n",
    "yaml_content = f\"\"\"\n",
    "# A.3 RGB+Depth Dataset Config\n",
    "path: {WORK_DIR.as_posix()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "nc: 1\n",
    "names: ['fresh_fruit_bunch']\n",
    "channels: 4\n",
    "\"\"\"\n",
    "\n",
    "config_path = WORK_DIR / 'dataset_rgbd.yaml'\n",
    "config_path.write_text(yaml_content)\n",
    "\n",
    "print(f\"Config saved: {config_path}\")\n",
    "print(\"\\nConfig content:\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Custom RGBD Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_depth_to_uint8(depth: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize depth to uint8 range\"\"\"\n",
    "    if depth.dtype == np.uint8:\n",
    "        return depth\n",
    "    depth_f = depth.astype(np.float32)\n",
    "    norm = cv2.normalize(depth_f, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return norm.astype(np.uint8)\n",
    "\n",
    "\n",
    "class RGBDDataset(YOLODataset):\n",
    "    \"\"\"Custom YOLO Dataset for RGBD (4-channel) input\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Fix buffer issue in Mosaic augmentation\n",
    "        try:\n",
    "            from collections import deque\n",
    "            buf = getattr(self, \"buffer\", None)\n",
    "            if buf is None or len(buf) == 0:\n",
    "                n = len(getattr(self, \"im_files\", []))\n",
    "                seed = list(range(min(n, 256)))\n",
    "                self.buffer = deque(seed, maxlen=1000)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def img2label_paths(img_paths):\n",
    "        \"\"\"Map image paths to label paths\"\"\"\n",
    "        label_paths = []\n",
    "        for p in img_paths:\n",
    "            p = str(p)\n",
    "            if (os.sep + \"images\" + os.sep) in p:\n",
    "                p = p.replace(os.sep + \"images\" + os.sep, os.sep + \"labels\" + os.sep)\n",
    "            elif (os.sep + \"rgb\" + os.sep) in p:\n",
    "                p = p.replace(os.sep + \"rgb\" + os.sep, os.sep + \"labels\" + os.sep)\n",
    "            label_paths.append(os.path.splitext(p)[0] + \".txt\")\n",
    "        return label_paths\n",
    "    \n",
    "    def load_image(self, i):\n",
    "        \"\"\"Load RGB and Depth, merge to 4-channel\"\"\"\n",
    "        f = self.im_files[i]\n",
    "        \n",
    "        # Load RGB\n",
    "        rgb = cv2.imread(f)\n",
    "        if rgb is None:\n",
    "            raise FileNotFoundError(f\"RGB not found: {f}\")\n",
    "        \n",
    "        h0, w0 = rgb.shape[:2]\n",
    "        \n",
    "        # Load Depth (from depth/ folder)\n",
    "        if (os.sep + \"images\" + os.sep) in f:\n",
    "            depth_path = f.replace(os.sep + \"images\" + os.sep, os.sep + \"depth\" + os.sep)\n",
    "        else:\n",
    "            depth_path = f.replace(os.sep + \"rgb\" + os.sep, os.sep + \"depth\" + os.sep)\n",
    "        \n",
    "        depth = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n",
    "        if depth is None:\n",
    "            raise FileNotFoundError(f\"Depth not found: {depth_path}\")\n",
    "        \n",
    "        # Process depth\n",
    "        if depth.ndim == 3:\n",
    "            depth = depth[:, :, 0]\n",
    "        \n",
    "        # Resize depth to match RGB if needed\n",
    "        if depth.shape[:2] != (h0, w0):\n",
    "            depth = cv2.resize(depth, (w0, h0), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Normalize and add channel dimension\n",
    "        depth = normalize_depth_to_uint8(depth)[:, :, None]\n",
    "        \n",
    "        # Stack RGB + Depth = 4 channels\n",
    "        img = np.concatenate([rgb, depth], axis=2)\n",
    "        \n",
    "        # Resize like YOLODataset\n",
    "        r = self.imgsz / max(h0, w0)\n",
    "        if r != 1:\n",
    "            interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA\n",
    "            img = cv2.resize(img, (int(w0 * r), int(h0 * r)), interpolation=interp)\n",
    "        \n",
    "        return img, (h0, w0), img.shape[:2]\n",
    "\n",
    "print(\"✓ RGBDDataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Custom Trainer & Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBDTrainer(DetectionTrainer):\n",
    "    \"\"\"Custom Trainer for RGBD dataset\"\"\"\n",
    "    \n",
    "    def build_dataset(self, img_path, mode=\"train\", batch=None):\n",
    "        \"\"\"Build RGBD dataset\"\"\"\n",
    "        stride_t = self.model.stride\n",
    "        stride = int(stride_t.max()) if hasattr(stride_t, \"max\") else int(stride_t)\n",
    "        \n",
    "        return RGBDDataset(\n",
    "            data=self.data,\n",
    "            task=self.args.task,\n",
    "            img_path=img_path,\n",
    "            imgsz=self.args.imgsz,\n",
    "            batch_size=batch,\n",
    "            augment=mode == \"train\",\n",
    "            hyp=self.args,\n",
    "            rect=mode == \"val\",\n",
    "            cache=self.args.cache,\n",
    "            single_cls=False,\n",
    "            stride=stride,\n",
    "            pad=0.0,\n",
    "            prefix=f\"{mode}: \",\n",
    "        )\n",
    "\n",
    "\n",
    "class RGBDValidator(DetectionValidator):\n",
    "    \"\"\"Custom Validator for RGBD dataset\"\"\"\n",
    "    \n",
    "    def build_dataset(self, img_path, mode=\"val\", batch=None):\n",
    "        \"\"\"Build RGBD dataset for validation\"\"\"\n",
    "        stride_t = getattr(self, \"stride\", 32)\n",
    "        stride = int(stride_t.max()) if hasattr(stride_t, \"max\") else int(stride_t)\n",
    "        \n",
    "        return RGBDDataset(\n",
    "            data=self.data,\n",
    "            task=self.args.task,\n",
    "            img_path=img_path,\n",
    "            imgsz=self.args.imgsz,\n",
    "            batch_size=batch,\n",
    "            augment=False,\n",
    "            hyp=self.args,\n",
    "            rect=True,\n",
    "            cache=self.args.cache,\n",
    "            single_cls=False,\n",
    "            stride=stride,\n",
    "            pad=0.0,\n",
    "            prefix=f\"{mode}: \",\n",
    "        )\n",
    "\n",
    "print(\"✓ RGBDTrainer and RGBDValidator defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Model Modification (4-Channel Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_first_conv_to_4ch(det_model):\n",
    "    \"\"\"\n",
    "    Modify YOLO model's first conv layer to accept 4 channels (RGB+Depth).\n",
    "    Copies RGB weights and initializes depth channel from mean of RGB.\n",
    "    \"\"\"\n",
    "    first = det_model.model[0]\n",
    "    conv = first.conv if hasattr(first, \"conv\") else first\n",
    "    \n",
    "    if conv.in_channels == 4:\n",
    "        print(\"Model already has 4 input channels\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Modifying first conv: {conv.in_channels} -> 4 channels\")\n",
    "    \n",
    "    # Create new 4-channel conv\n",
    "    new_conv = torch.nn.Conv2d(\n",
    "        in_channels=4,\n",
    "        out_channels=conv.out_channels,\n",
    "        kernel_size=conv.kernel_size,\n",
    "        stride=conv.stride,\n",
    "        padding=conv.padding,\n",
    "        bias=(conv.bias is not None),\n",
    "    )\n",
    "    \n",
    "    # Initialize weights\n",
    "    with torch.no_grad():\n",
    "        # Copy RGB weights (first 3 channels)\n",
    "        new_conv.weight[:, :conv.in_channels] = conv.weight\n",
    "        # Initialize depth channel (4th) from mean of RGB\n",
    "        new_conv.weight[:, conv.in_channels:] = conv.weight.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        if conv.bias is not None:\n",
    "            new_conv.bias[:] = conv.bias\n",
    "    \n",
    "    # Replace conv layer\n",
    "    if hasattr(first, \"conv\"):\n",
    "        first.conv = new_conv\n",
    "    else:\n",
    "        det_model.model[0] = new_conv\n",
    "    \n",
    "    # Update model config\n",
    "    det_model.model.yaml[\"ch\"] = 4\n",
    "    print(\"✓ Model modified for 4-channel input\")\n",
    "\n",
    "print(\"✓ adapt_first_conv_to_4ch function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Verify Dataset Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset counts\n",
    "train_dir = WORK_DIR / \"images\" / \"train\"\n",
    "val_dir = WORK_DIR / \"images\" / \"val\"\n",
    "test_dir = WORK_DIR / \"images\" / \"test\"\n",
    "\n",
    "print(\"Dataset counts:\")\n",
    "print(f\"  Train: {len(list(train_dir.glob('*.png')))} images\")\n",
    "print(f\"  Val:   {len(list(val_dir.glob('*.png')))} images\")\n",
    "print(f\"  Test:  {len(list(test_dir.glob('*.png')))} images\")\n",
    "\n",
    "# Clear old caches\n",
    "for p in WORK_DIR.rglob(\"*.cache\"):\n",
    "    try:\n",
    "        p.unlink()\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"✓ Cache cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "SEEDS = [42, 123, 456, 789, 101]\n",
    "EXP_PREFIX = 'exp_a3_rgbd'\n",
    "\n",
    "IMGSZ = 640\n",
    "EPOCHS = 100\n",
    "BATCH = 16\n",
    "PATIENCE = 30\n",
    "DEVICE = \"0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Training Config:\")\n",
    "print(f\"  Seeds: {SEEDS}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch: {BATCH}\")\n",
    "print(f\"  Image Size: {IMGSZ}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Patience: {PATIENCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with 5 seeds\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING A.3 RGBD (4-CH) - Seed {seed} ({SEEDS.index(seed)+1}/{len(SEEDS)})\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    exp_name = f\"{EXP_PREFIX}_seed{seed}\"\n",
    "    \n",
    "    # Set seeds\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # Load model and modify for 4-channel\n",
    "    model = YOLO(\"yolo11n.pt\")\n",
    "    adapt_first_conv_to_4ch(model.model)\n",
    "    \n",
    "    # Train with custom trainer\n",
    "    results = model.train(\n",
    "        data=str(config_path),\n",
    "        imgsz=IMGSZ,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH,\n",
    "        seed=seed,\n",
    "        device=DEVICE,\n",
    "        name=exp_name,\n",
    "        exist_ok=True,\n",
    "        patience=PATIENCE,\n",
    "        hsv_h=0.0,  # Disable HSV for fair RGBD comparison\n",
    "        hsv_s=0.0,\n",
    "        hsv_v=0.0,\n",
    "        trainer=RGBDTrainer,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSeed {seed} training complete!\")\n",
    "    print(f\"  mAP50: {results.results_dict.get('metrics/mAP50(B)', 0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "results_dict = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"\\n⚠️ Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Seed {seed}:\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = YOLO(str(model_path))\n",
    "    \n",
    "    # Validate on test set with custom validator\n",
    "    metrics = model.val(\n",
    "        data=str(config_path),\n",
    "        split=\"test\",\n",
    "        device=DEVICE,\n",
    "        name=f\"test_{EXP_PREFIX}_seed{seed}\",\n",
    "        exist_ok=True,\n",
    "        validator=RGBDValidator,\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results_dict[seed] = {\n",
    "        'mAP50': metrics.box.map50,\n",
    "        'mAP50-95': metrics.box.map,\n",
    "        'Precision': metrics.box.mp,\n",
    "        'Recall': metrics.box.mr\n",
    "    }\n",
    "    \n",
    "    print(f\"  mAP50:     {metrics.box.map50:.3f}\")\n",
    "    print(f\"  mAP50-95:  {metrics.box.map:.3f}\")\n",
    "    print(f\"  Precision: {metrics.box.mp:.3f}\")\n",
    "    print(f\"  Recall:    {metrics.box.mr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "df = pd.DataFrame(results_dict).T\n",
    "df.index.name = 'Seed'\n",
    "\n",
    "# Calculate mean and std\n",
    "avg = df.mean()\n",
    "std = df.std()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"A.3 RGB+DEPTH (REAL) - FINAL RESULTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"SUMMARY (Mean ± Std)\")\n",
    "print(\"-\"*60)\n",
    "for col in df.columns:\n",
    "    print(f\"  {col}: {avg[col]:.3f} ± {std[col]:.3f}\")\n",
    "\n",
    "# Store for saving\n",
    "summary_results = {\n",
    "    'df': df,\n",
    "    'avg': avg,\n",
    "    'std': std\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "output_file = KAGGLE_OUTPUT / 'a3_rgbd_results.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"A.3 RGB+Depth (Real) 4-Channel Results\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(\"Training: epochs=100, patience=30, HSV=disabled\\n\")\n",
    "    f.write(f\"Seeds: {SEEDS}\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Per-Seed Results:\\n\")\n",
    "    f.write(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "    f.write(\"\\n\\n\" + \"-\"*60 + \"\\n\")\n",
    "    f.write(\"Summary (Mean ± Std):\\n\")\n",
    "    for col in df.columns:\n",
    "        f.write(f\"  {col}: {avg[col]:.3f} ± {std[col]:.3f}\\n\")\n",
    "\n",
    "print(f\"✓ Results saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Create Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip archives for download\n",
    "if RUNS_PATH.exists():\n",
    "    shutil.make_archive(str(BASE_PATH / 'a3_runs'), 'zip', RUNS_PATH)\n",
    "    zip_size = (BASE_PATH / 'a3_runs.zip').stat().st_size / 1024 / 1024\n",
    "    print(f\"✓ a3_runs.zip: {zip_size:.1f} MB\")\n",
    "\n",
    "shutil.make_archive(str(BASE_PATH / 'a3_output'), 'zip', KAGGLE_OUTPUT)\n",
    "print(\"✓ a3_output.zip created\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDownload files from the Output tab:\")\n",
    "print(\"  - a3_runs.zip (training runs)\")\n",
    "print(\"  - a3_output.zip (results)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}