{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Depth Maps using Depth-Anything-V2\n",
    "\n",
    "**Purpose**: Generate synthetic depth maps from RGB images using Depth-Anything-V2 model\n",
    "\n",
    "**Model**: Depth-Anything-V2-Large (from HuggingFace)\n",
    "\n",
    "**Expected Time**: 20-30 minutes on GPU for ~400 images\n",
    "\n",
    "**Output**: Synthetic depth maps for train/val/test splits\n",
    "\n",
    "**Usage**: Prerequisite for A.4a (Synthetic Depth Only) and A.4b (RGB+Synthetic Depth)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Detect environment\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "\n",
    "# Set base paths\n",
    "if IS_KAGGLE:\n",
    "    BASE_PATH = Path('/kaggle/working')\n",
    "    RGB_DATASET_PATH = Path('/kaggle/input/ffb-localization')  # Adjust to your Kaggle dataset\n",
    "else:\n",
    "    BASE_PATH = Path(r'd:\\Work\\Assisten Dosen\\Anylabel\\Experiments')\n",
    "    RGB_DATASET_PATH = BASE_PATH / 'datasets' / 'ffb_localization'\n",
    "\n",
    "# Output path for synthetic depth\n",
    "SYNTHETIC_DEPTH_PATH = BASE_PATH / 'datasets' / 'depth_synthetic_da2_raw'\n",
    "\n",
    "os.chdir(BASE_PATH)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"RGB dataset: {RGB_DATASET_PATH}\")\n",
    "print(f\"Output path: {SYNTHETIC_DEPTH_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers torch torchvision pillow numpy opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Check GPU\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"⚠️ GPU not available, using CPU (will be slow)\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Depth-Anything-V2 Model\n",
    "\n",
    "Loading from HuggingFace: `depth-anything/Depth-Anything-V2-Large`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and processor\n",
    "MODEL_NAME = \"depth-anything/Depth-Anything-V2-Large\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "print(\"This may take a few minutes on first run...\\n\")\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForDepthEstimation.from_pretrained(MODEL_NAME)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ Model loaded successfully\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan RGB images\n",
    "def scan_rgb_images(base_path):\n",
    "    \"\"\"Scan RGB images from train/val/test splits\"\"\"\n",
    "    images = {}\n",
    "    splits = ['train', 'val', 'test']\n",
    "    \n",
    "    for split in splits:\n",
    "        split_path = base_path / 'images' / split\n",
    "        if not split_path.exists():\n",
    "            print(f\"⚠️ Path not found: {split_path}\")\n",
    "            images[split] = []\n",
    "            continue\n",
    "        \n",
    "        img_files = sorted(split_path.glob('*.png')) + sorted(split_path.glob('*.jpg'))\n",
    "        images[split] = img_files\n",
    "        print(f\"{split.upper()}: {len(img_files)} images\")\n",
    "    \n",
    "    total = sum(len(v) for v in images.values())\n",
    "    print(f\"\\nTotal images: {total}\")\n",
    "    return images\n",
    "\n",
    "print(\"Scanning RGB images...\\n\")\n",
    "rgb_images = scan_rgb_images(RGB_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Synthetic Depth Maps\n",
    "\n",
    "Process each RGB image and generate corresponding depth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_depth(rgb_image_path, model, processor, device):\n",
    "    \"\"\"Generate depth map from RGB image\"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(rgb_image_path).convert('RGB')\n",
    "    \n",
    "    # Prepare inputs\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth\n",
    "    \n",
    "    # Post-process\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=image.size[::-1],  # (height, width)\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    \n",
    "    # Convert to numpy\n",
    "    depth_np = prediction.squeeze().cpu().numpy()\n",
    "    \n",
    "    return depth_np\n",
    "\n",
    "def save_depth(depth_np, output_path):\n",
    "    \"\"\"Save depth map as 16-bit PNG\"\"\"\n",
    "    # Normalize to 0-65535 range\n",
    "    depth_min = depth_np.min()\n",
    "    depth_max = depth_np.max()\n",
    "    depth_normalized = (depth_np - depth_min) / (depth_max - depth_min)\n",
    "    depth_u16 = (depth_normalized * 65535).astype(np.uint16)\n",
    "    \n",
    "    # Save\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(output_path), depth_u16)\n",
    "    \n",
    "print(\"Helper functions defined ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images\n",
    "start_time = time.time()\n",
    "stats = {'success': 0, 'failed': 0}\n",
    "\n",
    "for split, img_list in rgb_images.items():\n",
    "    if not img_list:\n",
    "        print(f\"Skipping {split} (no images)\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {split.upper()} set ({len(img_list)} images)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for rgb_path in tqdm(img_list, desc=f\"{split}\"):\n",
    "        try:\n",
    "            # Generate depth\n",
    "            depth_np = generate_depth(rgb_path, model, processor, device)\n",
    "            \n",
    "            # Save depth\n",
    "            output_path = SYNTHETIC_DEPTH_PATH / split / rgb_path.name\n",
    "            save_depth(depth_np, output_path)\n",
    "            \n",
    "            stats['success'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Failed: {rgb_path.name} - {str(e)}\")\n",
    "            stats['failed'] += 1\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"GENERATION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Success: {stats['success']}\")\n",
    "print(f\"Failed: {stats['failed']}\")\n",
    "print(f\"Total time: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Avg time per image: {elapsed_time/stats['success']:.2f} seconds\")\n",
    "print(f\"\\nOutput saved to: {SYNTHETIC_DEPTH_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verification & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify output\n",
    "print(\"Verifying generated depth maps...\\n\")\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    depth_path = SYNTHETIC_DEPTH_PATH / split\n",
    "    if depth_path.exists():\n",
    "        depth_files = list(depth_path.glob('*.png'))\n",
    "        print(f\"{split.upper()}: {len(depth_files)} depth maps generated\")\n",
    "    else:\n",
    "        print(f\"{split.upper()}: No output directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_rgb_depth_pair(rgb_path, depth_path):\n",
    "    \"\"\"Visualize RGB and corresponding synthetic depth side by side\"\"\"\n",
    "    rgb = cv2.imread(str(rgb_path))\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    depth = cv2.imread(str(depth_path), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axes[0].imshow(rgb)\n",
    "    axes[0].set_title('RGB Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    im = axes[1].imshow(depth, cmap='turbo')\n",
    "    axes[1].set_title('Synthetic Depth')\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im, ax=axes[1], label='Depth (relative)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show 3 samples from train set\n",
    "train_rgb = rgb_images['train']\n",
    "if train_rgb:\n",
    "    print(\"Sample visualizations from train set:\\n\")\n",
    "    for i in range(min(3, len(train_rgb))):\n",
    "        rgb_path = train_rgb[i]\n",
    "        depth_path = SYNTHETIC_DEPTH_PATH / 'train' / rgb_path.name\n",
    "        if depth_path.exists():\n",
    "            print(f\"Sample {i+1}: {rgb_path.name}\")\n",
    "            visualize_rgb_depth_pair(rgb_path, depth_path)\n",
    "else:\n",
    "    print(\"No train images to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "After generating synthetic depth maps:\n",
    "\n",
    "1. Run `prepare_synthetic_depth_data.py` to organize and process depth maps\n",
    "2. This will create the `depth_synthetic_da2` dataset (3-channel, 0-255 normalized)\n",
    "3. Then you can run A.4a (Synthetic Depth Only) and A.4b (RGB+Synthetic Depth) experiments\n",
    "\n",
    "**Output Location**:\n",
    "- Raw synthetic depth (16-bit): `datasets/depth_synthetic_da2_raw/`\n",
    "- Processed (3-channel, 8-bit): `datasets/depth_synthetic_da2/` (after running prepare script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. ✅ Loaded Depth-Anything-V2-Large model\n",
    "2. ✅ Generated synthetic depth maps for all RGB images\n",
    "3. ✅ Saved as 16-bit PNG files\n",
    "4. ✅ Visualized samples\n",
    "\n",
    "**Performance**: Depth-Anything-V2 is a state-of-the-art monocular depth estimation model that can generate high-quality depth maps from single RGB images.\n",
    "\n",
    "**Next**: Run preparation script to normalize and format for YOLO training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
