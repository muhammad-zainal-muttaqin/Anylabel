{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14537315,"sourceType":"datasetVersion","datasetId":9284917}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"76f259fe-e590-4f29-bb8d-2c2fd1859b8c","cell_type":"code","source":"# =============================================================================\n# Cell 1: Clone Repository SAJA\n# =============================================================================\n!git clone https://github.com/DepthAnything/Depth-Anything-V2.git 2>/dev/null || echo \"Repo exists\"\nprint(\"✓ Repository cloned\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dd80dc19-d4b5-4adf-9f7f-9756775aaafb","cell_type":"code","source":"# =============================================================================\n# Cell 2: Patch untuk NumPy 2.x\n# =============================================================================\n# Patch transform.py\ntransform_file = '/kaggle/working/Depth-Anything-V2/depth_anything_v2/util/transform.py'\nwith open(transform_file, 'r') as f:\n    content = f.read()\ncontent = content.replace(\n    'sample[\"image\"] = cv2.resize(sample[\"image\"], (width, height), interpolation=self.__image_interpolation_method)',\n    'sample[\"image\"] = cv2.resize(sample[\"image\"], (int(width), int(height)), interpolation=self.__image_interpolation_method)'\n)\nwith open(transform_file, 'w') as f:\n    f.write(content)\n\n# Patch dpt.py\ndpt_file = '/kaggle/working/Depth-Anything-V2/depth_anything_v2/dpt.py'\nwith open(dpt_file, 'r') as f:\n    content = f.read()\ncontent = content.replace(\n    'depth = F.interpolate(depth[:, None], (h, w), mode=\"bilinear\", align_corners=True)[0, 0]',\n    'depth = F.interpolate(depth[:, None], (int(h), int(w)), mode=\"bilinear\", align_corners=True)[0, 0]'\n)\nwith open(dpt_file, 'w') as f:\n    f.write(content)\n\nprint(\"✅ Patched for NumPy 2.x\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"165de604-897f-4e62-898b-efd47207192b","cell_type":"code","source":"# =============================================================================\n# Cell 3: Import Libraries\n# =============================================================================\nimport os, sys, time, shutil, cv2, torch\nimport numpy as np\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\nsys.path.append('/kaggle/working/Depth-Anything-V2')\nfrom depth_anything_v2.dpt import DepthAnythingV2\n\nprint(f\"✓ NumPy: {np.__version__}\")\nprint(f\"✓ PyTorch: {torch.__version__}\")\nprint(f\"✓ CUDA: {torch.cuda.is_available()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"908d9d80-95a9-4a46-95ff-c2bc8bf63a8c","cell_type":"code","source":"# =============================================================================\n# Cell 4: Set Paths\n# =============================================================================\nIS_KAGGLE = os.path.exists('/kaggle/input')\nBASE_PATH = Path('/kaggle/working')\nRGB_DATASET_PATH = Path('/kaggle/input/ffb-localization-dataset/ffb_localization')\nSYNTHETIC_DEPTH_RAW = BASE_PATH / 'datasets' / 'depth_synthetic_da2_raw'\nYOLO_DATASET_PATH = BASE_PATH / 'datasets' / 'ffb_localization_depth_synthetic'\n\nprint(f\"RGB dataset exists: {RGB_DATASET_PATH.exists()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f04575ea-10b6-4143-8006-fdfcf55862fb","cell_type":"code","source":"# =============================================================================\n# Cell 5: Download Model\n# =============================================================================\n!mkdir -p /kaggle/working/checkpoints\n!wget -q -O /kaggle/working/checkpoints/depth_anything_v2_vitl.pth \\\n    https://huggingface.co/depth-anything/Depth-Anything-V2-Large/resolve/main/depth_anything_v2_vitl.pth\nprint(\"✅ Model downloaded\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"902fd595-31eb-4bb3-b34a-26d0bfca012d","cell_type":"code","source":"# =============================================================================\n# Cell 6: Load Model\n# =============================================================================\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = DepthAnythingV2(encoder=\"vitl\", features=256, out_channels=[256, 512, 1024, 1024])\nmodel.load_state_dict(torch.load(\"/kaggle/working/checkpoints/depth_anything_v2_vitl.pth\", \n                                  map_location=device, weights_only=True))\nmodel.to(device).eval()\nprint(f\"✅ Model loaded on {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"134ba6b3-aa8f-428b-9006-4fa5534f7d08","cell_type":"code","source":"# =============================================================================\n# Cell 7: Scan Images\n# =============================================================================\ndef scan_rgb_images(base_path):\n    images = {}\n    for split in ['train', 'val', 'test']:\n        p = base_path / 'images' / split\n        images[split] = sorted(list(p.glob('*.png')) + list(p.glob('*.jpg'))) if p.exists() else []\n        print(f\"{split}: {len(images[split])}\")\n    return images\n\nrgb_images = scan_rgb_images(RGB_DATASET_PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a4511ea1-a091-44ef-93b5-f7b1ebac3244","cell_type":"code","source":"# =============================================================================\n# Cell 8: Test Single Image\n# =============================================================================\nraw_img = cv2.imread(str(rgb_images['train'][0]))\ndepth = model.infer_image(raw_img)\nprint(f\"✅ Test OK! Depth shape: {depth.shape}, range: [{depth.min():.1f}, {depth.max():.1f}]\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7061791f-d4f8-4848-8dce-c51dd395d04d","cell_type":"code","source":"# =============================================================================\n# Cell 9: Generate All Depth Maps\n# =============================================================================\ndef save_depth_16bit(depth_np, path):\n    d_min, d_max = depth_np.min(), depth_np.max()\n    norm = (depth_np - d_min) / (d_max - d_min) if d_max > d_min else np.zeros_like(depth_np)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    cv2.imwrite(str(path), (norm * 65535).astype(np.uint16))\n\nstats = {'success': 0, 'failed': 0}\nstart = time.time()\n\nfor split in ['train', 'val', 'test']:\n    imgs = rgb_images.get(split, [])\n    if not imgs: continue\n    \n    print(f\"\\n=== {split.upper()} ({len(imgs)} images) ===\")\n    \n    # Create dirs\n    (YOLO_DATASET_PATH / 'images' / split).mkdir(parents=True, exist_ok=True)\n    (YOLO_DATASET_PATH / 'labels' / split).mkdir(parents=True, exist_ok=True)\n    (SYNTHETIC_DEPTH_RAW / split).mkdir(parents=True, exist_ok=True)\n    \n    # Copy labels\n    lbl_src = RGB_DATASET_PATH / 'labels' / split\n    if lbl_src.exists():\n        for f in lbl_src.glob('*.txt'):\n            shutil.copy2(f, YOLO_DATASET_PATH / 'labels' / split / f.name)\n    \n    # Generate depth\n    for p in tqdm(imgs, desc=split):\n        try:\n            img = cv2.imread(str(p))\n            depth = model.infer_image(img)\n            save_depth_16bit(depth, SYNTHETIC_DEPTH_RAW / split / p.name)\n            save_depth_16bit(depth, YOLO_DATASET_PATH / 'images' / split / p.name)\n            stats['success'] += 1\n        except Exception as e:\n            stats['failed'] += 1\n\nprint(f\"\\n✅ Done: {stats['success']} success, {stats['failed']} failed\")\nprint(f\"⏱️ Time: {(time.time()-start)/60:.1f} min\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a5bc6a5f-d3f1-47b2-ad2e-b746540c73bf","cell_type":"code","source":"# =============================================================================\n# Cell 10: Create YAML\n# =============================================================================\nfrom datetime import datetime\nyaml_content = f\"\"\"path: {YOLO_DATASET_PATH.as_posix()}\ntrain: images/train\nval: images/val\ntest: images/test\nnc: 1\nnames: ['fresh_fruit_bunch']\n\"\"\"\n(YOLO_DATASET_PATH / 'dataset.yaml').write_text(yaml_content)\nprint(\"✅ YAML saved\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dbd5db3b-fa18-44e1-9f0a-f08f4344b4fe","cell_type":"code","source":"# =============================================================================\n# Cell 11: Create Archives\n# =============================================================================\nshutil.make_archive('/kaggle/working/ffb_synthetic_depth_yolo', 'zip', YOLO_DATASET_PATH)\nshutil.make_archive('/kaggle/working/ffb_synthetic_depth_raw', 'zip', SYNTHETIC_DEPTH_RAW)\nprint(f\"✅ ffb_synthetic_depth_yolo.zip: {os.path.getsize('/kaggle/working/ffb_synthetic_depth_yolo.zip')/1024/1024:.1f} MB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}