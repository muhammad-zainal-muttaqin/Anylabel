{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:26:20.431757Z",
     "iopub.status.busy": "2026-01-27T13:26:20.430708Z",
     "iopub.status.idle": "2026-01-27T13:26:31.742478Z",
     "shell.execute_reply": "2026-01-27T13:26:31.741745Z",
     "shell.execute_reply.started": "2026-01-27T13:26:20.431720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Setup & Imports\n",
    "# ============================================================\n",
    "!pip install -q ultralytics\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:26:31.744420Z",
     "iopub.status.busy": "2026-01-27T13:26:31.744057Z",
     "iopub.status.idle": "2026-01-27T13:26:31.750077Z",
     "shell.execute_reply": "2026-01-27T13:26:31.749423Z",
     "shell.execute_reply.started": "2026-01-27T13:26:31.744394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Dataset Path Setup\n",
    "# ============================================================\n",
    "if IS_KAGGLE:\n",
    "    DATASET_DIR = Path(\"/kaggle/input/ffb-localization-rgbd-dataset/ffb_localization_rgbd\")\n",
    "    WORK_DIR = Path(\"/kaggle/working/ffb_localization_rgbd\")\n",
    "    BASE_PATH = Path(\"/kaggle/working\")\n",
    "else:\n",
    "    BASE_PATH = Path(r\"D:/Work/Assisten Dosen/Anylabel/Experiments\")\n",
    "    DATASET_DIR = BASE_PATH / \"datasets\" / \"ffb_localization_rgbd\"\n",
    "    WORK_DIR = BASE_PATH / \"working\" / \"ffb_localization_rgbd\"\n",
    "\n",
    "RUNS_PATH = BASE_PATH / 'runs' / 'detect'\n",
    "KAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\n",
    "KAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset Dir: {DATASET_DIR}\")\n",
    "print(f\"Work Dir: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:26:31.751229Z",
     "iopub.status.busy": "2026-01-27T13:26:31.750930Z",
     "iopub.status.idle": "2026-01-27T13:27:29.657608Z",
     "shell.execute_reply": "2026-01-27T13:27:29.656835Z",
     "shell.execute_reply.started": "2026-01-27T13:26:31.751199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Create Pre-merged RGBD 4-Channel PNG Images\n",
    "# ============================================================\n",
    "def create_rgbd_dataset(root: Path, work_root: Path) -> None:\n",
    "    splits = (\"train\", \"val\", \"test\")\n",
    "    \n",
    "    for split in splits:\n",
    "        rgb_dir = root / \"rgb\" / split\n",
    "        depth_dir = root / \"depth\" / split\n",
    "        label_dir = root / \"labels\" / split\n",
    "        \n",
    "        if not all([rgb_dir.exists(), depth_dir.exists(), label_dir.exists()]):\n",
    "            print(f\"Warning: Missing folders for {split}\")\n",
    "            continue\n",
    "        \n",
    "        rgb_files = {p.name for p in rgb_dir.glob(\"*.png\")}\n",
    "        depth_files = {p.name for p in depth_dir.glob(\"*.png\")}\n",
    "        label_files = {p.with_suffix(\".png\").name for p in label_dir.glob(\"*.txt\")}\n",
    "        \n",
    "        keep = rgb_files & depth_files & label_files\n",
    "        print(f\"{split}: Keep={len(keep)}\")\n",
    "        \n",
    "        images_dir = work_root / \"images\" / split\n",
    "        images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        labels_out_dir = work_root / \"labels\" / split\n",
    "        labels_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for fname in keep:\n",
    "            dst_rgbd = images_dir / fname\n",
    "            \n",
    "            if not dst_rgbd.exists():\n",
    "                rgb = cv2.imread(str(rgb_dir / fname), cv2.IMREAD_COLOR)\n",
    "                depth = cv2.imread(str(depth_dir / fname), cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if rgb is None or depth is None:\n",
    "                    continue\n",
    "                \n",
    "                if depth.shape[:2] != rgb.shape[:2]:\n",
    "                    depth = cv2.resize(depth, (rgb.shape[1], rgb.shape[0]))\n",
    "                \n",
    "                rgbd = np.dstack([rgb, depth])\n",
    "                cv2.imwrite(str(dst_rgbd), rgbd)\n",
    "            \n",
    "            src_label = label_dir / fname.replace(\".png\", \".txt\")\n",
    "            dst_label = labels_out_dir / fname.replace(\".png\", \".txt\")\n",
    "            if not dst_label.exists():\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "        \n",
    "        sample = list(images_dir.glob(\"*.png\"))[0]\n",
    "        test_img = cv2.imread(str(sample), cv2.IMREAD_UNCHANGED)\n",
    "        print(f\"  -> shape: {test_img.shape}\")\n",
    "\n",
    "create_rgbd_dataset(DATASET_DIR, WORK_DIR)\n",
    "\n",
    "for p in WORK_DIR.rglob(\"*.cache\"):\n",
    "    try:\n",
    "        p.unlink()\n",
    "    except:\n",
    "        pass\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:27:29.658922Z",
     "iopub.status.busy": "2026-01-27T13:27:29.658632Z",
     "iopub.status.idle": "2026-01-27T13:27:33.457644Z",
     "shell.execute_reply": "2026-01-27T13:27:33.457020Z",
     "shell.execute_reply.started": "2026-01-27T13:27:29.658901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Monkey-Patch Ultralytics imread\n",
    "# ============================================================\n",
    "import ultralytics.utils.patches as patches\n",
    "\n",
    "_original_imread = patches.imread\n",
    "\n",
    "def imread_4ch(filename, flags=cv2.IMREAD_UNCHANGED):\n",
    "    return _original_imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "patches.imread = imread_4ch\n",
    "print(\"✅ Patched imread\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "print(\"✅ YOLO imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:27:33.458761Z",
     "iopub.status.busy": "2026-01-27T13:27:33.458445Z",
     "iopub.status.idle": "2026-01-27T13:27:33.463945Z",
     "shell.execute_reply": "2026-01-27T13:27:33.463043Z",
     "shell.execute_reply.started": "2026-01-27T13:27:33.458736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Create Dataset Config YAML dengan channels: 4\n",
    "# ============================================================\n",
    "config_content = f\"\"\"path: {WORK_DIR}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: 1\n",
    "channels: 4\n",
    "\n",
    "names:\n",
    "  0: ffb\n",
    "\"\"\"\n",
    "\n",
    "config_path = WORK_DIR / \"dataset_rgbd.yaml\"\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_content)\n",
    "print(f\"✅ Config saved: {config_path}\")\n",
    "print(\"   (includes channels: 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:36:32.995053Z",
     "iopub.status.busy": "2026-01-27T13:36:32.994374Z",
     "iopub.status.idle": "2026-01-27T13:36:33.008430Z",
     "shell.execute_reply": "2026-01-27T13:36:33.007638Z",
     "shell.execute_reply.started": "2026-01-27T13:36:32.995000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Custom Trainer & Validator with 4-Channel Support (FIXED)\n",
    "# ============================================================\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer, DetectionValidator\n",
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "\n",
    "def convert_conv_to_4ch(conv_layer):\n",
    "    \"\"\"Convert a conv layer from 3ch to 4ch input\"\"\"\n",
    "    if conv_layer.in_channels == 4:\n",
    "        return conv_layer\n",
    "    \n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=4,\n",
    "        out_channels=conv_layer.out_channels,\n",
    "        kernel_size=conv_layer.kernel_size,\n",
    "        stride=conv_layer.stride,\n",
    "        padding=conv_layer.padding,\n",
    "        bias=conv_layer.bias is not None\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        new_conv.weight[:, :3, :, :] = conv_layer.weight.clone()\n",
    "        new_conv.weight[:, 3:4, :, :] = conv_layer.weight.mean(dim=1, keepdim=True)\n",
    "        if conv_layer.bias is not None:\n",
    "            new_conv.bias = nn.Parameter(conv_layer.bias.clone())\n",
    "    \n",
    "    return new_conv\n",
    "\n",
    "\n",
    "def ensure_model_4ch(model):\n",
    "    \"\"\"Ensure model has 4-channel input, works with different model types\"\"\"\n",
    "    try:\n",
    "        # For AutoBackend wrapped models\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'model'):\n",
    "            first_conv = model.model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting AutoBackend model...\")\n",
    "                model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "        # For direct DetectionModel\n",
    "        elif hasattr(model, 'model') and hasattr(model.model[0], 'conv'):\n",
    "            first_conv = model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting DetectionModel...\")\n",
    "                model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f\"[4ch] Warning: {e}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "class RGBD4ChValidator(DetectionValidator):\n",
    "    \"\"\"Validator yang convert model ke 4ch sebelum validasi\"\"\"\n",
    "    \n",
    "    def __call__(self, trainer=None, model=None):\n",
    "        \"\"\"Override untuk convert model ke 4ch\"\"\"\n",
    "        # Call parent first to setup everything\n",
    "        # Model akan di-load dari path oleh parent class\n",
    "        return super().__call__(trainer, model)\n",
    "    \n",
    "    def setup_model(self):\n",
    "        \"\"\"Override: setelah model di-load, convert ke 4ch\"\"\"\n",
    "        super().setup_model()\n",
    "        \n",
    "        # self.model sudah di-set oleh parent\n",
    "        if self.model is not None:\n",
    "            ensure_model_4ch(self.model)\n",
    "            print(f\"[Validator] Model 4ch ready\")\n",
    "\n",
    "\n",
    "class RGBD4ChTrainer(DetectionTrainer):\n",
    "    \"\"\"Trainer yang convert model ke 4-channel\"\"\"\n",
    "    \n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup model lalu convert ke 4-channel\"\"\"\n",
    "        super().setup_model()\n",
    "        \n",
    "        first_conv = self.model.model[0].conv\n",
    "        \n",
    "        if first_conv.in_channels == 4:\n",
    "            print(\"[Trainer] Model sudah 4-channel\")\n",
    "            return\n",
    "        \n",
    "        print(f\"[Trainer] Converting to 4-channel...\")\n",
    "        self.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "        print(f\"[Trainer] ✅ Converted! Shape: {self.model.model[0].conv.weight.shape}\")\n",
    "    \n",
    "    def get_validator(self):\n",
    "        \"\"\"Return custom validator\"\"\"\n",
    "        self.loss_names = \"box_loss\", \"cls_loss\", \"dfl_loss\"\n",
    "        return RGBD4ChValidator(\n",
    "            self.test_loader, \n",
    "            save_dir=self.save_dir, \n",
    "            args=self.args,\n",
    "            _callbacks=self.callbacks\n",
    "        )\n",
    "\n",
    "print(\"✅ Custom Trainer & Validator defined (FIXED)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:36:37.694272Z",
     "iopub.status.busy": "2026-01-27T13:36:37.693724Z",
     "iopub.status.idle": "2026-01-27T13:36:37.699139Z",
     "shell.execute_reply": "2026-01-27T13:36:37.698449Z",
     "shell.execute_reply.started": "2026-01-27T13:36:37.694242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Training Configuration\n",
    "# ============================================================\n",
    "EXP_PREFIX = \"exp_a3_rgbd\"\n",
    "SEEDS = [42, 123, 456, 789, 101]\n",
    "EPOCHS = 100\n",
    "IMGSZ = 640\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Seeds: {SEEDS}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:36:42.495602Z",
     "iopub.status.busy": "2026-01-27T13:36:42.494887Z",
     "iopub.status.idle": "2026-01-27T13:38:30.675078Z",
     "shell.execute_reply": "2026-01-27T13:38:30.674238Z",
     "shell.execute_reply.started": "2026-01-27T13:36:42.495569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Training Loop\n",
    "# ============================================================\n",
    "results_all = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING - Seed {seed} ({SEEDS.index(seed)+1}/{len(SEEDS)})\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    trainer = RGBD4ChTrainer(overrides={\n",
    "        'model': 'yolo11n.pt',\n",
    "        'data': str(config_path),\n",
    "        'imgsz': IMGSZ,\n",
    "        'epochs': EPOCHS,\n",
    "        'batch': BATCH_SIZE,\n",
    "        'device': DEVICE,\n",
    "        'seed': seed,\n",
    "        'name': f\"{EXP_PREFIX}_seed{seed}\",\n",
    "        'project': str(RUNS_PATH),\n",
    "        'exist_ok': True,\n",
    "        'pretrained': True,\n",
    "        'patience': 30,\n",
    "        'val': True,\n",
    "        'hsv_h': 0.0,\n",
    "        'hsv_s': 0.0,\n",
    "        'hsv_v': 0.0,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.1,\n",
    "        'scale': 0.5,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 1.0,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0,\n",
    "        'erasing': 0.0,\n",
    "    })\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    results_all[seed] = {\n",
    "        'model_path': str(RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✅ Seed {seed} completed!\")\n",
    "    \n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:38:41.557166Z",
     "iopub.status.busy": "2026-01-27T13:38:41.556505Z",
     "iopub.status.idle": "2026-01-27T13:39:04.732019Z",
     "shell.execute_reply": "2026-01-27T13:39:04.731285Z",
     "shell.execute_reply.started": "2026-01-27T13:38:41.557128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Evaluation dengan Custom Validator\n",
    "# ============================================================\n",
    "results_dict = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    \n",
    "    model = YOLO(str(model_path))\n",
    "    \n",
    "    # Convert ke 4ch jika perlu\n",
    "    first_conv = model.model.model[0].conv\n",
    "    if first_conv.in_channels == 3:\n",
    "        print(\"  Converting to 4ch...\")\n",
    "        model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "    \n",
    "    metrics = model.val(\n",
    "        data=str(config_path),\n",
    "        split=\"test\",\n",
    "        device=DEVICE,\n",
    "        name=f\"test_{EXP_PREFIX}_seed{seed}\",\n",
    "        exist_ok=True,\n",
    "    )\n",
    "    \n",
    "    results_dict[seed] = {\n",
    "        'mAP50': metrics.box.map50,\n",
    "        'mAP50-95': metrics.box.map,\n",
    "        'Precision': metrics.box.mp,\n",
    "        'Recall': metrics.box.mr\n",
    "    }\n",
    "    \n",
    "    print(f\"  mAP50: {metrics.box.map50:.3f}, mAP50-95: {metrics.box.map:.3f}\")\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T13:39:15.328031Z",
     "iopub.status.busy": "2026-01-27T13:39:15.327327Z",
     "iopub.status.idle": "2026-01-27T13:39:20.087207Z",
     "shell.execute_reply": "2026-01-27T13:39:20.086537Z",
     "shell.execute_reply.started": "2026-01-27T13:39:15.327994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 10: Summary & Save\n",
    "# ============================================================\n",
    "if results_dict:\n",
    "    df = pd.DataFrame(results_dict).T\n",
    "    df.index.name = 'Seed'\n",
    "    avg = df.mean()\n",
    "    std = df.std()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"A.3 RGB+DEPTH - FINAL RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"SUMMARY (Mean ± Std)\")\n",
    "    print(\"-\"*60)\n",
    "    for col in df.columns:\n",
    "        print(f\"  {col}: {avg[col]:.3f} ± {std[col]:.3f}\")\n",
    "\n",
    "    output_file = KAGGLE_OUTPUT / 'a3_rgbd_results.txt'\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"A.3 RGB+Depth Results\\n\")\n",
    "        f.write(f\"Generated: {datetime.now()}\\n\\n\")\n",
    "        f.write(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "        f.write(\"\\n\\nSummary:\\n\")\n",
    "        for col in df.columns:\n",
    "            f.write(f\"  {col}: {avg[col]:.3f} ± {std[col]:.3f}\\n\")\n",
    "    print(f\"\\n✅ Saved: {output_file}\")\n",
    "\n",
    "if RUNS_PATH.exists():\n",
    "    shutil.make_archive(str(BASE_PATH / 'a3_runs'), 'zip', RUNS_PATH)\n",
    "    print(\"✅ a3_runs.zip created\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9288121,
     "sourceId": 14542234,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
