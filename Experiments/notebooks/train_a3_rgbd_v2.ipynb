{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.3 RGB+Depth 4-Channel with Reset BN\n",
    "\n",
    "**Experiment:** A.3 - RGB+Depth Fusion (V2)\n",
    "**Input:** RGB + Real Depth (4-channel RGBD)\n",
    "**Objective:** Test fusion of RGB with real depth sensor data\n",
    "**Classes:** 1 (fresh_fruit_bunch)\n",
    "\n",
    "## Key Features\n",
    "1. **4-Channel Input**: RGB (3) + Depth (1) = 4 channels\n",
    "2. **Custom Trainer**: RGBD4ChTrainer with 4-channel support\n",
    "3. **First Conv Adaptation**: Convert 3ch to 4ch input layer\n",
    "4. **Reset BN**: Domain adaptation for RGBD input\n",
    "\n",
    "## Prerequisites\n",
    "- Upload RGB dataset as: `ffb-localization-rgbd-dataset`\n",
    "- Or use local dataset at: `datasets/ffb_localization_rgbd/`\n",
    "\n",
    "## Uniform Augmentation (All Experiments)\n",
    "- translate: 0.1\n",
    "- scale: 0.5\n",
    "- fliplr: 0.5\n",
    "- hsv_h: 0.0 (disabled for uniformity)\n",
    "- hsv_s: 0.0 (disabled for uniformity)\n",
    "- hsv_v: 0.0 (disabled for uniformity)\n",
    "- erasing: 0.0\n",
    "- mosaic: 0.0\n",
    "- mixup: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 1: Environment Setup & Imports\n",
    "# =============================================================================\n",
    "!pip install -q ultralytics\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Auto-detect environment\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') or os.path.exists('/kaggle')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    BASE_PATH = Path('/kaggle/working')\n",
    "    DATASET_DIR = Path('/kaggle/input/ffb-localization-rgbd-dataset/ffb_localization_rgbd')\n",
    "else:\n",
    "    BASE_PATH = Path('D:/Work/Assisten Dosen/Anylabel/Experiments')\n",
    "    DATASET_DIR = BASE_PATH / 'datasets' / 'ffb_localization_rgbd'\n",
    "\n",
    "RUNS_PATH = BASE_PATH / 'runs' / 'detect'\n",
    "WORK_DIR = BASE_PATH / 'working' / 'rgbd_4ch'\n",
    "KAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\n",
    "KAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"A.3 RGB+DEPTH (4-CH) - ENVIRONMENT SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "print(f\"Dataset Dir: {DATASET_DIR}\")\n",
    "print(f\"Work Dir: {WORK_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Configuration - AUGMENT_PARAMS\n",
    "# =============================================================================\n",
    "# Uniform augmentation parameters (consistent across all experiments)\n",
    "AUGMENT_PARAMS = {\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'hsv_h': 0.0,  # Disabled for uniformity\n",
    "    'hsv_s': 0.0,  # Disabled for uniformity\n",
    "    'hsv_v': 0.0,  # Disabled for uniformity\n",
    "    'erasing': 0.0,\n",
    "    'mosaic': 0.0,\n",
    "    'mixup': 0.0,\n",
    "    'degrees': 0.0,\n",
    "    'copy_paste': 0.0,\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "SEEDS = [42, 123, 456, 789, 101]\n",
    "EXP_PREFIX = 'exp_a3_rgbd_v2'\n",
    "EPOCHS = 100\n",
    "PATIENCE = 30\n",
    "IMGSZ = 640\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Experiment: A.3 RGB+Depth (4-CH) (V2)\")\n",
    "print(f\"Model: YOLOv11n\")\n",
    "print(f\"Seeds: {SEEDS} ({len(SEEDS)} runs)\")\n",
    "print(f\"Epochs: {EPOCHS} (patience: {PATIENCE})\")\n",
    "print(f\"Image Size: {IMGSZ}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"EXP_PREFIX: {EXP_PREFIX}\")\n",
    "print(\"\\nUniform Augmentation:\")\n",
    "for key, value in AUGMENT_PARAMS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\nSpecial Features:\")\n",
    "print(\"  - 4-Channel input (RGB+Depth)\")\n",
    "print(\"  - Custom 4-channel trainer\")\n",
    "print(\"  - Reset BatchNorm for domain adaptation\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Helper Functions - convert_conv_to_4ch() and reset_bn_stats()\n",
    "# =============================================================================\n",
    "def convert_conv_to_4ch(conv_layer):\n",
    "    \"\"\"\n",
    "    Convert a conv layer from 3ch to 4ch input.\n",
    "    Copies RGB weights and initializes depth channel as mean of RGB.\n",
    "    \"\"\"\n",
    "    if conv_layer.in_channels == 4:\n",
    "        return conv_layer\n",
    "    \n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=4,\n",
    "        out_channels=conv_layer.out_channels,\n",
    "        kernel_size=conv_layer.kernel_size,\n",
    "        stride=conv_layer.stride,\n",
    "        padding=conv_layer.padding,\n",
    "        bias=conv_layer.bias is not None\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        new_conv.weight[:, :3, :, :] = conv_layer.weight.clone()\n",
    "        new_conv.weight[:, 3:4, :, :] = conv_layer.weight.mean(dim=1, keepdim=True)\n",
    "        if conv_layer.bias is not None:\n",
    "            new_conv.bias = nn.Parameter(conv_layer.bias.clone())\n",
    "    \n",
    "    return new_conv\n",
    "\n",
    "\n",
    "def reset_bn_stats(model, train_loader, num_batches=100, device='cuda'):\n",
    "    \"\"\"\n",
    "    Reset running stats BatchNorm dengan 100 batch training data.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.reset_running_stats()\n",
    "            module.momentum = 0.1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            imgs = batch['img'].to(device) if isinstance(batch, dict) else batch[0].to(device)\n",
    "            _ = model(imgs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def ensure_model_4ch(model):\n",
    "    \"\"\"\n",
    "    Ensure model has 4-channel input.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'model'):\n",
    "            first_conv = model.model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting model...\")\n",
    "                model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "        elif hasattr(model, 'model') and hasattr(model.model[0], 'conv'):\n",
    "            first_conv = model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting model...\")\n",
    "                model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f\"[4ch] Warning: {e}\")\n",
    "    return False\n",
    "\n",
    "print(\"âœ“ Helper functions defined: convert_conv_to_4ch(), reset_bn_stats(), ensure_model_4ch()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Create 4-Channel RGBD Dataset\n",
    "# =============================================================================\n",
    "def create_rgbd_dataset(root: Path, work_root: Path) -> None:\n",
    "    \"\"\"\n",
    "    Create 4-channel RGBD dataset by combining RGB (3ch) + Depth (1ch).\n",
    "    Saves as 4-channel PNG images.\n",
    "    \"\"\"\n",
    "    splits = (\"train\", \"val\", \"test\")\n",
    "    \n",
    "    for split in splits:\n",
    "        rgb_dir = root / \"rgb\" / split\n",
    "        depth_dir = root / \"depth\" / split\n",
    "        label_dir = root / \"labels\" / split\n",
    "        \n",
    "        if not all([rgb_dir.exists(), depth_dir.exists(), label_dir.exists()]):\n",
    "            print(f\"Warning: Missing folders for {split}\")\n",
    "            continue\n",
    "        \n",
    "        rgb_files = {p.name for p in rgb_dir.glob(\"*.png\")}\n",
    "        depth_files = {p.name for p in depth_dir.glob(\"*.png\")}\n",
    "        label_files = {p.with_suffix(\".png\").name for p in label_dir.glob(\"*.txt\")}\n",
    "        \n",
    "        keep = rgb_files & depth_files & label_files\n",
    "        print(f\"{split}: {len(keep)} samples\")\n",
    "        \n",
    "        images_dir = work_root / \"images\" / split\n",
    "        images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        labels_out_dir = work_root / \"labels\" / split\n",
    "        labels_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for fname in tqdm(keep, desc=f\"Creating 4ch ({split})\"):\n",
    "            dst_rgbd = images_dir / fname\n",
    "            \n",
    "            if not dst_rgbd.exists():\n",
    "                rgb = cv2.imread(str(rgb_dir / fname), cv2.IMREAD_COLOR)\n",
    "                depth = cv2.imread(str(depth_dir / fname), cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if rgb is None or depth is None:\n",
    "                    continue\n",
    "                \n",
    "                if depth.shape[:2] != rgb.shape[:2]:\n",
    "                    depth = cv2.resize(depth, (rgb.shape[1], rgb.shape[0]))\n",
    "                \n",
    "                rgbd = np.dstack([rgb, depth])\n",
    "                cv2.imwrite(str(dst_rgbd), rgbd)\n",
    "            \n",
    "            src_label = label_dir / fname.replace(\".png\", \".txt\")\n",
    "            dst_label = labels_out_dir / fname.replace(\".png\", \".txt\")\n",
    "            if not dst_label.exists():\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "        \n",
    "        # Verify\n",
    "        sample = list(images_dir.glob(\"*.png\"))[0]\n",
    "        test_img = cv2.imread(str(sample), cv2.IMREAD_UNCHANGED)\n",
    "        print(f\"  -> Verified shape: {test_img.shape}\")\n",
    "\n",
    "# Create dataset\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING 4-CHANNEL RGBD DATASET\")\n",
    "print(\"=\"*60)\n",
    "create_rgbd_dataset(DATASET_DIR, WORK_DIR)\n",
    "\n",
    "# Clear cache files\n",
    "for p in WORK_DIR.rglob(\"*.cache\"):\n",
    "    try:\n",
    "        p.unlink()\n",
    "    except:\n",
    "        pass\n",
    "print(\"\\nâœ“ Dataset preparation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Custom RGBD4ChTrainer and RGBD4ChValidator Classes\n",
    "# =============================================================================\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer, DetectionValidator\n",
    "from ultralytics.data import build_dataloader\n",
    "\n",
    "class RGBD4ChValidator(DetectionValidator):\n",
    "    \"\"\"\n",
    "    Validator yang convert model ke 4ch sebelum validasi.\n",
    "    \"\"\"\n",
    "    def setup_model(self):\n",
    "        super().setup_model()\n",
    "        if self.model is not None:\n",
    "            ensure_model_4ch(self.model)\n",
    "            print(\"[Validator] Model 4ch ready\")\n",
    "\n",
    "\n",
    "class RGBD4ChTrainer(DetectionTrainer):\n",
    "    \"\"\"\n",
    "    Trainer yang convert model ke 4-channel.\n",
    "    \"\"\"\n",
    "    def setup_model(self):\n",
    "        super().setup_model()\n",
    "        \n",
    "        first_conv = self.model.model[0].conv\n",
    "        \n",
    "        if first_conv.in_channels == 4:\n",
    "            print(\"[Trainer] Model sudah 4-channel\")\n",
    "            return\n",
    "        \n",
    "        print(f\"[Trainer] Converting to 4-channel...\")\n",
    "        self.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "        print(f\"[Trainer] âœ… Converted! Shape: {self.model.model[0].conv.weight.shape}\")\n",
    "    \n",
    "    def get_validator(self):\n",
    "        self.loss_names = \"box_loss\", \"cls_loss\", \"dfl_loss\"\n",
    "        return RGBD4ChValidator(\n",
    "            self.test_loader,\n",
    "            save_dir=self.save_dir,\n",
    "            args=self.args,\n",
    "            _callbacks=self.callbacks\n",
    "        )\n",
    "\n",
    "print(\"âœ… Custom RGBD4ChTrainer and RGBD4ChValidator defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Create Dataset YAML\n",
    "# =============================================================================\n",
    "yaml_content = f\"\"\"\n",
    "# A.3 RGB+Depth 4-Channel Dataset Configuration\n",
    "path: {WORK_DIR}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: 1\n",
    "channels: 4\n",
    "\n",
    "names:\n",
    "  0: fresh_fruit_bunch\n",
    "\"\"\"\n",
    "\n",
    "config_path = WORK_DIR / \"dataset_rgbd_v2.yaml\"\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"âœ… Config saved: {config_path}\")\n",
    "print(\"\\nConfig contents:\")\n",
    "print(\"-\"*40)\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Cell 7: Training Loop with 4-Channel Conversion and BN Reset (Fixed)\n# =============================================================================\nresults_all = {}\ntraining_times = {}\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING LOOP\")\nprint(\"=\"*60)\n\nfor idx, seed in enumerate(SEEDS, 1):\n    start_time = time.time()\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING A.3 RGBD - Seed {seed} ({idx}/{len(SEEDS)})\")\n    print(f\"{'='*60}\")\n    \n    # Set seeds\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    \n    try:\n        # Create trainer\n        trainer = RGBD4ChTrainer(overrides={\n            'model': 'yolo11n.pt',\n            'data': str(config_path),\n            'imgsz': IMGSZ,\n            'epochs': EPOCHS,\n            'batch': BATCH_SIZE,\n            'device': DEVICE,\n            'seed': seed,\n            'name': f\"{EXP_PREFIX}_seed{seed}\",\n            'project': str(RUNS_PATH),\n            'exist_ok': True,\n            'pretrained': True,\n            'patience': PATIENCE,\n            'val': True,\n            **AUGMENT_PARAMS,\n        })\n        \n        # Pindahkan model ke GPU dulu\n        trainer.model.model.to(DEVICE)\n        \n        # Reset BN stats using dummy input (compatible with all Ultralytics versions)\n        print(\"Resetting BatchNorm statistics...\")\n        trainer.model.model.train()\n        \n        # Reset running stats for all BN layers\n        for module in trainer.model.model.modules():\n            if isinstance(module, nn.BatchNorm2d):\n                module.reset_running_stats()\n                module.momentum = 0.1\n        \n        # Forward pass dengan dummy images (4-channel) untuk update BN stats\n        dummy_input = torch.randn(BATCH_SIZE, 4, IMGSZ, IMGSZ).to(DEVICE)\n        with torch.no_grad():\n            for _ in range(10):\n                _ = trainer.model.model(dummy_input)\n        \n        print(\"âœ“ BN reset complete\")\n        \n        # Train\n        trainer.train()\n        \n        elapsed = time.time() - start_time\n        training_times[seed] = elapsed\n        \n        # Fix: Simpan hasil dengan struktur yang benar\n        results_all[seed] = {\n            'model_path': str(RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"),\n            'epochs_trained': EPOCHS,\n            'completed': True,\n        }\n        \n        print(f\"\\nâœ“ Seed {seed} completed!\")\n        print(f\"  Time: {elapsed/60:.1f} minutes\")\n        \n    except Exception as e:\n        print(f\"\\nâœ— Seed {seed} failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        results_all[seed] = {'error': str(e), 'completed': False}\n    \n    # Cleanup\n    if 'trainer' in locals():\n        del trainer\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING LOOP COMPLETED\")\nprint(\"=\"*60)\n\n# Print summary\nprint(\"\\nðŸ“Š RESULTS SUMMARY:\")\nsuccessful = sum(1 for r in results_all.values() if r.get('completed', False))\nprint(f\"Successful: {successful}/{len(SEEDS)}\")\nfor seed, res in results_all.items():\n    if res.get('completed', False):\n        print(f\"  Seed {seed}: âœ“ Completed\")\n    else:\n        print(f\"  Seed {seed}: âœ— FAILED - {res.get('error', 'Unknown')[:50]}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 8: Evaluation\n",
    "# =============================================================================\n",
    "results_dict = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(str(model_path))\n",
    "        \n",
    "        # Convert to 4ch if needed\n",
    "        first_conv = model.model.model[0].conv\n",
    "        if first_conv.in_channels == 3:\n",
    "            print(\"  Converting to 4ch...\")\n",
    "            model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "        \n",
    "        metrics = model.val(\n",
    "            data=str(config_path),\n",
    "            split=\"test\",\n",
    "            device=DEVICE,\n",
    "            name=f\"test_{EXP_PREFIX}_seed{seed}\",\n",
    "            exist_ok=True,\n",
    "        )\n",
    "        \n",
    "        results_dict[seed] = {\n",
    "            'mAP50': metrics.box.map50,\n",
    "            'mAP50-95': metrics.box.map,\n",
    "            'Precision': metrics.box.mp,\n",
    "            'Recall': metrics.box.mr,\n",
    "        }\n",
    "        \n",
    "        print(f\"  mAP50: {metrics.box.map50:.4f}, mAP50-95: {metrics.box.map:.4f}\")\n",
    "        \n",
    "        del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Evaluation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 9: Summary\n",
    "# =============================================================================\n",
    "if results_dict:\n",
    "    df = pd.DataFrame(results_dict).T\n",
    "    df.index.name = 'Seed'\n",
    "    \n",
    "    avg = df.mean()\n",
    "    std = df.std()\n",
    "    min_vals = df.min()\n",
    "    max_vals = df.max()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"A.3 RGB+DEPTH (4-CH) (V2) - FINAL RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"STATISTICAL SUMMARY\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"{'Metric':<15} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n",
    "    print(\"-\"*60)\n",
    "    for col in df.columns:\n",
    "        print(f\"{col:<15} {avg[col]:>10.4f} {std[col]:>10.4f} {min_vals[col]:>10.4f} {max_vals[col]:>10.4f}\")\n",
    "    \n",
    "    best_seed = df['mAP50'].idxmax()\n",
    "    print(f\"\\nâœ“ Best Seed: {best_seed} (mAP50: {df.loc[best_seed, 'mAP50']:.4f})\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 10: Save Results\n",
    "# =============================================================================\n",
    "output_file = KAGGLE_OUTPUT / 'a3_rgbd_v2_results.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"A.3 RGB+Depth (4-CH) (V2) Results\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Local'}\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Configuration:\\n\")\n",
    "    f.write(f\"  Model: YOLOv11n\\n\")\n",
    "    f.write(f\"  Input: 4-Channel (RGB+Depth)\\n\")\n",
    "    f.write(f\"  Epochs: {EPOCHS} (patience: {PATIENCE})\\n\")\n",
    "    f.write(f\"  Image Size: {IMGSZ}\\n\")\n",
    "    f.write(f\"  Batch Size: {BATCH_SIZE}\\n\")\n",
    "    f.write(f\"  Seeds: {SEEDS}\\n\")\n",
    "    f.write(\"\\nUniform Augmentation:\\n\")\n",
    "    for key, value in AUGMENT_PARAMS.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "    f.write(\"\\nSpecial Features:\\n\")\n",
    "    f.write(\"  - 4-Channel input (RGB+Depth)\\n\")\n",
    "    f.write(\"  - Custom RGBD4ChTrainer\\n\")\n",
    "    f.write(\"  - Reset BatchNorm for domain adaptation\\n\")\n",
    "    \n",
    "    if results_dict:\n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"Per-Seed Results:\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "        \n",
    "        f.write(\"\\n\\n\" + \"-\"*60 + \"\\n\")\n",
    "        f.write(\"Summary (Mean Â± Std):\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        for col in df.columns:\n",
    "            f.write(f\"  {col}: {avg[col]:.4f} Â± {std[col]:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Seed: {best_seed}\\n\")\n",
    "\n",
    "print(f\"\\nâœ“ Results saved: {output_file}\")\n",
    "\n",
    "# JSON output\n",
    "json_output = {\n",
    "    'experiment': 'A.3',\n",
    "    'variant': 'V2',\n",
    "    'seeds': SEEDS,\n",
    "    'config': {\n",
    "        'model': 'yolo11n',\n",
    "        'input_channels': 4,\n",
    "        'epochs': EPOCHS,\n",
    "        'patience': PATIENCE,\n",
    "        'imgsz': IMGSZ,\n",
    "        'batch': BATCH_SIZE,\n",
    "        'augmentation': AUGMENT_PARAMS,\n",
    "        'reset_bn': True,\n",
    "    },\n",
    "    'results': {str(k): v for k, v in results_dict.items()},\n",
    "    'summary': {\n",
    "        'mean': {k: float(v) for k, v in avg.items()},\n",
    "        'std': {k: float(v) for k, v in std.items()},\n",
    "        'best_seed': int(best_seed) if results_dict else None,\n",
    "    } if results_dict else None,\n",
    "}\n",
    "\n",
    "json_file = KAGGLE_OUTPUT / 'a3_rgbd_v2_results.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(json_output, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ JSON saved: {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 11: Create Archives\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING ARCHIVES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if RUNS_PATH.exists():\n",
    "    runs_zip = BASE_PATH / 'a3_rgbd_v2_runs.zip'\n",
    "    shutil.make_archive(str(runs_zip.with_suffix('')), 'zip', RUNS_PATH)\n",
    "    size_mb = runs_zip.stat().st_size / 1024 / 1024\n",
    "    print(f\"âœ“ a3_rgbd_v2_runs.zip: {size_mb:.1f} MB\")\n",
    "\n",
    "output_zip = BASE_PATH / 'a3_rgbd_v2_output.zip'\n",
    "shutil.make_archive(str(output_zip.with_suffix('')), 'zip', KAGGLE_OUTPUT)\n",
    "size_mb = output_zip.stat().st_size / 1024 / 1024\n",
    "print(f\"âœ“ a3_rgbd_v2_output.zip: {size_mb:.1f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL DONE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDownload from Output tab:\")\n",
    "print(\"  - a3_rgbd_v2_runs.zip (training runs)\")\n",
    "print(\"  - a3_rgbd_v2_output.zip (results)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}