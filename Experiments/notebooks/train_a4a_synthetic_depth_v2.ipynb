{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.4a Synthetic Depth Only with Reset BN\n",
    "\n",
    "**Experiment:** A.4a - Synthetic Depth\n",
    "**Input:** Synthetic depth maps (3-channel, generated by Depth-Anything-V2)\n",
    "**Objective:** Test if synthetic depth can replace real depth sensor\n",
    "**Classes:** 1 (fresh_fruit_bunch)\n",
    "\n",
    "## Workflow\n",
    "1. Environment setup with auto-detection (Kaggle vs Local)\n",
    "2. Install dependencies\n",
    "3. Dataset preparation and verification\n",
    "4. Training with 5 seeds (42, 123, 456, 789, 101)\n",
    "5. Reset BatchNorm statistics for synthetic depth domain adaptation\n",
    "6. Evaluation on test set\n",
    "7. Results summary with mean Â± std deviation\n",
    "\n",
    "## Prerequisites\n",
    "- Run `generate_synthetic_depth.ipynb` first\n",
    "- Upload output as Kaggle dataset: `ffb-synthetic-depth`\n",
    "\n",
    "## Uniform Augmentation (All Experiments)\n",
    "- translate: 0.1\n",
    "- scale: 0.5\n",
    "- fliplr: 0.5\n",
    "- hsv_h: 0.0 (disabled for uniformity)\n",
    "- hsv_s: 0.0 (disabled for uniformity)\n",
    "- hsv_v: 0.0 (disabled for uniformity)\n",
    "- erasing: 0.0\n",
    "- mosaic: 0.0\n",
    "- mixup: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 1: Environment Setup & Auto-Detection\n",
    "# =============================================================================\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import shutil\n",
    "import gc\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Auto-detect Kaggle vs Local environment\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') or os.path.exists('/kaggle')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    BASE_PATH = Path('/kaggle/working')\n",
    "    DATASET_PATH = Path('/kaggle/input/ffb-synthetic-depth')\n",
    "else:\n",
    "    BASE_PATH = Path('D:/Work/Assisten Dosen/Anylabel/Experiments')\n",
    "    DATASET_PATH = BASE_PATH / 'datasets' / 'ffb_localization_depth_synthetic'\n",
    "\n",
    "RUNS_PATH = BASE_PATH / 'runs' / 'detect'\n",
    "KAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\n",
    "KAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"A.4a SYNTHETIC DEPTH ONLY - ENVIRONMENT SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"Base Path: {BASE_PATH}\")\n",
    "print(f\"Dataset Path: {DATASET_PATH}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Install and Imports\n",
    "# =============================================================================\n",
    "!pip install -q ultralytics\n",
    "\n",
    "# Import after installation\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.data import build_dataloader\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"\\nâœ“ Ultralytics installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Configuration with AUGMENT_PARAMS\n",
    "# =============================================================================\n",
    "# Uniform augmentation parameters (consistent across all experiments)\n",
    "AUGMENT_PARAMS = {\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'hsv_h': 0.0,  # Disabled for uniformity\n",
    "    'hsv_s': 0.0,  # Disabled for uniformity\n",
    "    'hsv_v': 0.0,  # Disabled for uniformity\n",
    "    'erasing': 0.0,\n",
    "    'mosaic': 0.0,\n",
    "    'mixup': 0.0,\n",
    "    'degrees': 0.0,\n",
    "    'copy_paste': 0.0,\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "SEEDS = [42, 123, 456, 789, 101]\n",
    "EXP_PREFIX = 'exp_a4a_synthetic_v2'\n",
    "EPOCHS = 100\n",
    "PATIENCE = 30\n",
    "IMGSZ = 640\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Experiment: A.4a Synthetic Depth Only (V2)\")\n",
    "print(f\"Model: YOLOv11n\")\n",
    "print(f\"Seeds: {SEEDS} ({len(SEEDS)} runs)\")\n",
    "print(f\"Epochs: {EPOCHS} (patience: {PATIENCE})\")\n",
    "print(f\"Image Size: {IMGSZ}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"\\nUniform Augmentation:\")\n",
    "for key, value in AUGMENT_PARAMS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\nSpecial: Reset BatchNorm for synthetic depth domain adaptation\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Reset BN Helper Function (same as A.2)\n",
    "# =============================================================================\n",
    "def reset_bn_stats(model, train_loader, num_batches=100, device='cuda'):\n",
    "    \"\"\"\n",
    "    Reset running stats BatchNorm dengan 100 batch training data.\n",
    "    Dipanggil setelah load pretrained weights untuk domain adaptation.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Reset running stats\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.reset_running_stats()\n",
    "            module.momentum = 0.1  # Higher momentum for faster adaptation\n",
    "    \n",
    "    # Forward pass untuk update running stats\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            imgs = batch['img'].to(device) if isinstance(batch, dict) else batch[0].to(device)\n",
    "            _ = model(imgs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"âœ“ reset_bn_stats function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Dataset Verification and YAML\n",
    "# =============================================================================\n",
    "# Verify dataset structure\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_dir = DATASET_PATH / 'images' / split\n",
    "    lbl_dir = DATASET_PATH / 'labels' / split\n",
    "    \n",
    "    if img_dir.exists():\n",
    "        imgs = len(list(img_dir.glob('*.png')))\n",
    "    else:\n",
    "        imgs = 0\n",
    "        \n",
    "    if lbl_dir.exists():\n",
    "        lbls = len(list(lbl_dir.glob('*.txt')))\n",
    "    else:\n",
    "        lbls = 0\n",
    "    \n",
    "    status = \"âœ“\" if imgs > 0 and lbls > 0 else \"âœ—\"\n",
    "    print(f\"{status} {split:6}: {imgs:4} images, {lbls:4} labels\")\n",
    "\n",
    "# Create YAML config\n",
    "yaml_content = f\"\"\"\n",
    "# A.4a Synthetic Depth Only Dataset Configuration\n",
    "path: {DATASET_PATH}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: 1\n",
    "names: ['fresh_fruit_bunch']\n",
    "\"\"\"\n",
    "\n",
    "config_path = BASE_PATH / 'dataset_synthetic_v2.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"\\nâœ“ YAML config created: {config_path}\")\n",
    "print(\"\\nConfig contents:\")\n",
    "print(\"-\"*40)\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Cell 6: Training Loop with reset_bn_stats() (Fixed)\n# =============================================================================\nresults_all = {}\ntraining_times = {}\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING LOOP\")\nprint(\"=\"*60)\n\nfor idx, seed in enumerate(SEEDS, 1):\n    start_time = time.time()\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING A.4a SYNTHETIC DEPTH - Seed {seed} ({idx}/{len(SEEDS)})\")\n    print(f\"{'='*60}\")\n    \n    # Set seeds for reproducibility\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    \n    try:\n        # Load model\n        model = YOLO('yolo11n.pt')\n        \n        # Pindahkan model ke GPU dulu\n        model.model.to(DEVICE)\n        \n        # Reset BN stats using dummy input (compatible with all Ultralytics versions)\n        print(\"Resetting BatchNorm statistics...\")\n        model.model.train()\n        \n        # Reset running stats for all BN layers\n        for module in model.model.modules():\n            if isinstance(module, nn.BatchNorm2d):\n                module.reset_running_stats()\n                module.momentum = 0.1\n        \n        # Forward pass dengan dummy images untuk update BN stats\n        dummy_input = torch.randn(BATCH_SIZE, 3, IMGSZ, IMGSZ).to(DEVICE)\n        with torch.no_grad():\n            for _ in range(10):\n                _ = model.model(dummy_input)\n        \n        print(\"âœ“ BN reset complete\")\n        \n        # Train\n        results = model.train(\n            data=str(config_path),\n            epochs=EPOCHS,\n            patience=PATIENCE,\n            seed=seed,\n            name=f\"{EXP_PREFIX}_seed{seed}\",\n            project=str(RUNS_PATH),\n            exist_ok=True,\n            imgsz=IMGSZ,\n            batch=BATCH_SIZE,\n            device=DEVICE,\n            **AUGMENT_PARAMS,\n        )\n        \n        elapsed = time.time() - start_time\n        training_times[seed] = elapsed\n        \n        # Fix: Akses metrics yang benar\n        results_all[seed] = {\n            'model_path': str(RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"),\n            'epochs_trained': EPOCHS,\n            'mAP50_val': results.box.map50 if hasattr(results, 'box') else 0,\n            'mAP50_95_val': results.box.map if hasattr(results, 'box') else 0,\n        }\n        \n        print(f\"\\nâœ“ Seed {seed} completed!\")\n        print(f\"  Epochs: {EPOCHS}\")\n        print(f\"  Val mAP50: {results_all[seed]['mAP50_val']:.4f}\")\n        print(f\"  Val mAP50-95: {results_all[seed]['mAP50_95_val']:.4f}\")\n        print(f\"  Time: {elapsed/60:.1f} minutes\")\n        \n    except Exception as e:\n        print(f\"\\nâœ— Seed {seed} failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        results_all[seed] = {'error': str(e)}\n    \n    # Memory cleanup\n    del model\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING LOOP COMPLETED\")\nprint(\"=\"*60)\n\n# Print summary\nprint(\"\\nðŸ“Š RESULTS SUMMARY:\")\nfor seed, res in results_all.items():\n    if 'error' not in res:\n        print(f\"  Seed {seed}: mAP50={res['mAP50_val']:.4f}, mAP50-95={res['mAP50_95_val']:.4f}\")\n    else:\n        print(f\"  Seed {seed}: FAILED - {res['error'][:50]}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 7: Evaluation\n",
    "# =============================================================================\n",
    "results_dict = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / 'weights' / 'best.pt'\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"âœ— Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(str(model_path))\n",
    "        metrics = model.val(data=str(config_path), split='test', device=DEVICE)\n",
    "        \n",
    "        results_dict[seed] = {\n",
    "            'mAP50': metrics.box.map50,\n",
    "            'mAP50-95': metrics.box.map,\n",
    "            'Precision': metrics.box.mp,\n",
    "            'Recall': metrics.box.mr,\n",
    "        }\n",
    "        \n",
    "        print(f\"  mAP50:     {metrics.box.map50:.4f}\")\n",
    "        print(f\"  mAP50-95:  {metrics.box.map:.4f}\")\n",
    "        print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "        print(f\"  Recall:    {metrics.box.mr:.4f}\")\n",
    "        \n",
    "        del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Evaluation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 8: Summary\n",
    "# =============================================================================\n",
    "if results_dict:\n",
    "    df = pd.DataFrame(results_dict).T\n",
    "    df.index.name = 'Seed'\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg = df.mean()\n",
    "    std = df.std()\n",
    "    min_vals = df.min()\n",
    "    max_vals = df.max()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"A.4a SYNTHETIC DEPTH ONLY (V2) - FINAL RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"STATISTICAL SUMMARY\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"{'Metric':<15} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n",
    "    print(\"-\"*60)\n",
    "    for col in df.columns:\n",
    "        print(f\"{col:<15} {avg[col]:>10.4f} {std[col]:>10.4f} {min_vals[col]:>10.4f} {max_vals[col]:>10.4f}\")\n",
    "    \n",
    "    # Best seed\n",
    "    best_seed = df['mAP50'].idxmax()\n",
    "    print(f\"\\nâœ“ Best Seed: {best_seed} (mAP50: {df.loc[best_seed, 'mAP50']:.4f})\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 9: Save Results\n",
    "# =============================================================================\n",
    "output_file = KAGGLE_OUTPUT / 'a4a_synthetic_v2_results.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"A.4a Synthetic Depth Only (V2) Results\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Local'}\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Configuration:\\n\")\n",
    "    f.write(\"  Model: YOLOv11n\\n\")\n",
    "    f.write(\"  Depth Source: Depth-Anything-V2 (Synthetic)\\n\")\n",
    "    f.write(f\"  Epochs: {EPOCHS} (patience: {PATIENCE})\\n\")\n",
    "    f.write(f\"  Image Size: {IMGSZ}\\n\")\n",
    "    f.write(f\"  Batch Size: {BATCH_SIZE}\\n\")\n",
    "    f.write(f\"  Seeds: {SEEDS}\\n\")\n",
    "    f.write(\"\\nUniform Augmentation:\\n\")\n",
    "    for key, value in AUGMENT_PARAMS.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "    f.write(\"\\nSpecial Features:\\n\")\n",
    "    f.write(\"  - Reset BatchNorm statistics for synthetic depth domain adaptation\\n\")\n",
    "    \n",
    "    if results_dict:\n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"Per-Seed Results:\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "        \n",
    "        f.write(\"\\n\\n\" + \"-\"*60 + \"\\n\")\n",
    "        f.write(\"Summary (Mean Â± Std):\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        for col in df.columns:\n",
    "            f.write(f\"  {col}: {avg[col]:.4f} Â± {std[col]:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Seed: {best_seed}\\n\")\n",
    "\n",
    "print(f\"\\nâœ“ Results saved: {output_file}\")\n",
    "\n",
    "# Also save as JSON for programmatic access\n",
    "json_output = {\n",
    "    'experiment': 'A.4a',\n",
    "    'variant': 'V2',\n",
    "    'seeds': SEEDS,\n",
    "    'config': {\n",
    "        'model': 'yolo11n',\n",
    "        'depth_source': 'synthetic',\n",
    "        'epochs': EPOCHS,\n",
    "        'patience': PATIENCE,\n",
    "        'imgsz': IMGSZ,\n",
    "        'batch': BATCH_SIZE,\n",
    "        'augmentation': AUGMENT_PARAMS,\n",
    "        'reset_bn': True,\n",
    "    },\n",
    "    'results': {str(k): v for k, v in results_dict.items()},\n",
    "    'summary': {\n",
    "        'mean': {k: float(v) for k, v in avg.items()},\n",
    "        'std': {k: float(v) for k, v in std.items()},\n",
    "        'best_seed': int(best_seed) if results_dict else None,\n",
    "    } if results_dict else None,\n",
    "}\n",
    "\n",
    "json_file = KAGGLE_OUTPUT / 'a4a_synthetic_v2_results.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(json_output, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ JSON saved: {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 10: Create Archives\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING ARCHIVES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Archive training runs\n",
    "if RUNS_PATH.exists():\n",
    "    runs_zip = BASE_PATH / 'a4a_synthetic_v2_runs.zip'\n",
    "    shutil.make_archive(str(runs_zip.with_suffix('')), 'zip', RUNS_PATH)\n",
    "    size_mb = runs_zip.stat().st_size / 1024 / 1024\n",
    "    print(f\"âœ“ a4a_synthetic_v2_runs.zip: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"âœ— No runs directory found\")\n",
    "\n",
    "# Archive outputs\n",
    "output_zip = BASE_PATH / 'a4a_synthetic_v2_output.zip'\n",
    "shutil.make_archive(str(output_zip.with_suffix('')), 'zip', KAGGLE_OUTPUT)\n",
    "size_mb = output_zip.stat().st_size / 1024 / 1024\n",
    "print(f\"âœ“ a4a_synthetic_v2_output.zip: {size_mb:.1f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL DONE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDownload from Output tab:\")\n",
    "print(\"  - a4a_synthetic_v2_runs.zip (training runs)\")\n",
    "print(\"  - a4a_synthetic_v2_output.zip (results)\")"
   ]
  }
 ]
}