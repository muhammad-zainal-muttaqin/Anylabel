{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfab5498",
   "metadata": {},
   "source": [
    "# A.4b - RGB + Synthetic Depth (4-Channel) Training - FIXED\n",
    "\n",
    "**Experiment:** A.4b  \n",
    "**Input:** RGB + Synthetic Depth (4-channel RGBD)  \n",
    "**Objective:** Test fusion of RGB with synthetic depth (Depth-Anything-V2)  \n",
    "**Classes:** 1 (fresh_fruit_bunch)\n",
    "\n",
    "## FIX Applied\n",
    "This version includes proper 4-channel support:\n",
    "1. Monkey-patch `imread` to read 4 channels\n",
    "2. Custom `RGBD4ChTrainer` and `RGBD4ChValidator`\n",
    "3. `channels: 4` in YAML config\n",
    "\n",
    "## Prerequisites\n",
    "1. Upload RGB dataset as: `ffb-localization-dataset`\n",
    "2. Upload Synthetic Depth dataset as: `ffb-synthetic-depth`\n",
    "\n",
    "## Training Config\n",
    "- Model: YOLOv11n\n",
    "- Epochs: 100\n",
    "- Patience: 30\n",
    "- Seeds: 42, 123, 456, 789, 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 1: Setup & Install\n",
    "# =============================================================================\n",
    "!pip install -q ultralytics\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "path_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Path Setup\n",
    "# =============================================================================\n",
    "RGB_DATASET = Path('/kaggle/input/ffb-localization-dataset/ffb_localization')\n",
    "DEPTH_DATASET = Path('/kaggle/input/ffb-synthetic-depth')\n",
    "BASE_PATH = Path('/kaggle/working')\n",
    "RUNS_PATH = BASE_PATH / 'runs' / 'detect'\n",
    "RGBD_DATASET = BASE_PATH / 'rgbd_4ch'\n",
    "KAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\n",
    "KAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"RGB Dataset: {RGB_DATASET} (exists: {RGB_DATASET.exists()})\")\n",
    "print(f\"Depth Dataset: {DEPTH_DATASET} (exists: {DEPTH_DATASET.exists()})\")\n",
    "print(f\"Output RGBD: {RGBD_DATASET}\")\n",
    "\n",
    "# Verify datasets\n",
    "for split in ['train', 'val', 'test']:\n",
    "    rgb_imgs = len(list((RGB_DATASET / 'images' / split).glob('*.png')))\n",
    "    depth_imgs = len(list((DEPTH_DATASET / 'images' / split).glob('*.png')))\n",
    "    rgb_lbls = len(list((RGB_DATASET / 'labels' / split).glob('*.txt')))\n",
    "    print(f\"  {split}: RGB={rgb_imgs}, Depth={depth_imgs}, Labels={rgb_lbls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_4ch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Create 4-Channel RGBD Dataset\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING 4-CHANNEL RGBD DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nProcessing {split.upper()}...\")\n",
    "    \n",
    "    rgb_img_dir = RGB_DATASET / 'images' / split\n",
    "    depth_img_dir = DEPTH_DATASET / 'images' / split\n",
    "    rgb_lbl_dir = RGB_DATASET / 'labels' / split\n",
    "    \n",
    "    # Create output directories\n",
    "    rgbd_img_dir = RGBD_DATASET / 'images' / split\n",
    "    rgbd_lbl_dir = RGBD_DATASET / 'labels' / split\n",
    "    rgbd_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    rgbd_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get RGB files\n",
    "    rgb_files = sorted(list(rgb_img_dir.glob('*.png')))\n",
    "    \n",
    "    for rgb_path in tqdm(rgb_files, desc=f\"Creating 4-ch images ({split})\"):\n",
    "        # Load RGB (3 channels)\n",
    "        rgb = cv2.imread(str(rgb_path))\n",
    "        if rgb is None:\n",
    "            print(f\"  Warning: Could not read {rgb_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Load synthetic depth (1 channel)\n",
    "        depth_path = depth_img_dir / rgb_path.name\n",
    "        depth = cv2.imread(str(depth_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if depth is None:\n",
    "            print(f\"  Warning: Could not read {depth_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Resize depth if needed\n",
    "        if depth.shape[:2] != rgb.shape[:2]:\n",
    "            depth = cv2.resize(depth, (rgb.shape[1], rgb.shape[0]))\n",
    "        \n",
    "        # Combine RGB (3) + Depth (1) = 4 channels\n",
    "        depth_expanded = depth[:, :, np.newaxis]\n",
    "        rgbd_4ch = np.concatenate([rgb, depth_expanded], axis=2)\n",
    "        \n",
    "        # Save 4-channel image\n",
    "        output_img_path = rgbd_img_dir / rgb_path.name\n",
    "        cv2.imwrite(str(output_img_path), rgbd_4ch)\n",
    "    \n",
    "    # Copy labels\n",
    "    label_files = list(rgb_lbl_dir.glob('*.txt'))\n",
    "    for lbl_path in label_files:\n",
    "        shutil.copy(str(lbl_path), str(rgbd_lbl_dir / lbl_path.name))\n",
    "    \n",
    "    img_count = len(list(rgbd_img_dir.glob('*.png')))\n",
    "    lbl_count = len(list(rgbd_lbl_dir.glob('*.txt')))\n",
    "    print(f\"  Done: {img_count} images, {lbl_count} labels\")\n",
    "\n",
    "# Verify sample\n",
    "sample_img = list((RGBD_DATASET / 'images' / 'train').glob('*.png'))[0]\n",
    "img = cv2.imread(str(sample_img), cv2.IMREAD_UNCHANGED)\n",
    "print(f\"\\nSample image shape: {img.shape} (should be H x W x 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Write YAML Config with channels: 4\n",
    "# =============================================================================\n",
    "config_content = f\"\"\"# A.4b RGB+Synthetic Depth 4-Channel Dataset\n",
    "path: {RGBD_DATASET}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: 1\n",
    "channels: 4\n",
    "\n",
    "names:\n",
    "  0: fresh_fruit_bunch\n",
    "\"\"\"\n",
    "\n",
    "config_path = RGBD_DATASET / 'dataset_rgbd_synthetic.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(f\"YAML saved: {config_path}\")\n",
    "print(\"(includes channels: 4)\")\n",
    "print(config_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monkey_patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Monkey-Patch Ultralytics imread for 4-Channel Support\n",
    "# =============================================================================\n",
    "import ultralytics.utils.patches as patches\n",
    "\n",
    "_original_imread = patches.imread\n",
    "\n",
    "def imread_4ch(filename, flags=cv2.IMREAD_UNCHANGED):\n",
    "    \"\"\"Always read with IMREAD_UNCHANGED to preserve 4 channels\"\"\"\n",
    "    return _original_imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "patches.imread = imread_4ch\n",
    "print(\"Patched imread for 4-channel support\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "print(\"YOLO imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Custom Trainer & Validator with 4-Channel Support\n",
    "# =============================================================================\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer, DetectionValidator\n",
    "\n",
    "def convert_conv_to_4ch(conv_layer):\n",
    "    \"\"\"Convert a conv layer from 3ch to 4ch input\"\"\"\n",
    "    if conv_layer.in_channels == 4:\n",
    "        return conv_layer\n",
    "    \n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=4,\n",
    "        out_channels=conv_layer.out_channels,\n",
    "        kernel_size=conv_layer.kernel_size,\n",
    "        stride=conv_layer.stride,\n",
    "        padding=conv_layer.padding,\n",
    "        bias=conv_layer.bias is not None\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Copy RGB weights\n",
    "        new_conv.weight[:, :3, :, :] = conv_layer.weight.clone()\n",
    "        # Initialize depth channel as mean of RGB\n",
    "        new_conv.weight[:, 3:4, :, :] = conv_layer.weight.mean(dim=1, keepdim=True)\n",
    "        if conv_layer.bias is not None:\n",
    "            new_conv.bias = nn.Parameter(conv_layer.bias.clone())\n",
    "    \n",
    "    return new_conv\n",
    "\n",
    "\n",
    "def ensure_model_4ch(model):\n",
    "    \"\"\"Ensure model has 4-channel input\"\"\"\n",
    "    try:\n",
    "        # For AutoBackend wrapped models\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'model'):\n",
    "            first_conv = model.model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting AutoBackend model...\")\n",
    "                model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "        # For direct DetectionModel\n",
    "        elif hasattr(model, 'model') and hasattr(model.model[0], 'conv'):\n",
    "            first_conv = model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting DetectionModel...\")\n",
    "                model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f\"[4ch] Warning: {e}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "class RGBD4ChValidator(DetectionValidator):\n",
    "    \"\"\"Validator that converts model to 4ch before validation\"\"\"\n",
    "    \n",
    "    def setup_model(self):\n",
    "        \"\"\"Override: after model is loaded, convert to 4ch\"\"\"\n",
    "        super().setup_model()\n",
    "        if self.model is not None:\n",
    "            ensure_model_4ch(self.model)\n",
    "            print(f\"[Validator] Model 4ch ready\")\n",
    "\n",
    "\n",
    "class RGBD4ChTrainer(DetectionTrainer):\n",
    "    \"\"\"Trainer that converts model to 4-channel\"\"\"\n",
    "    \n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup model then convert to 4-channel\"\"\"\n",
    "        super().setup_model()\n",
    "        \n",
    "        first_conv = self.model.model[0].conv\n",
    "        \n",
    "        if first_conv.in_channels == 4:\n",
    "            print(\"[Trainer] Model already 4-channel\")\n",
    "            return\n",
    "        \n",
    "        print(f\"[Trainer] Converting to 4-channel...\")\n",
    "        self.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "        print(f\"[Trainer] Converted! Shape: {self.model.model[0].conv.weight.shape}\")\n",
    "    \n",
    "    def get_validator(self):\n",
    "        \"\"\"Return custom validator\"\"\"\n",
    "        self.loss_names = \"box_loss\", \"cls_loss\", \"dfl_loss\"\n",
    "        return RGBD4ChValidator(\n",
    "            self.test_loader, \n",
    "            save_dir=self.save_dir, \n",
    "            args=self.args,\n",
    "            _callbacks=self.callbacks\n",
    "        )\n",
    "\n",
    "print(\"Custom Trainer & Validator defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 7: Training Configuration\n",
    "# =============================================================================\n",
    "EXP_PREFIX = \"exp_a4b_rgbd_synth\"\n",
    "SEEDS = [42, 123, 456, 789, 101]\n",
    "EPOCHS = 100\n",
    "IMGSZ = 640\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Experiment: A.4b RGB+Synthetic Depth (4-Channel) - FIXED\")\n",
    "print(f\"Seeds: {SEEDS}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 8: Training Loop with Custom Trainer\n",
    "# =============================================================================\n",
    "results_all = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING A.4b RGBD SYNTHETIC - Seed {seed} ({SEEDS.index(seed)+1}/{len(SEEDS)})\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Use custom trainer for 4-channel support\n",
    "    trainer = RGBD4ChTrainer(overrides={\n",
    "        'model': 'yolo11n.pt',\n",
    "        'data': str(config_path),\n",
    "        'imgsz': IMGSZ,\n",
    "        'epochs': EPOCHS,\n",
    "        'batch': BATCH_SIZE,\n",
    "        'device': DEVICE,\n",
    "        'seed': seed,\n",
    "        'name': f\"{EXP_PREFIX}_seed{seed}\",\n",
    "        'project': str(RUNS_PATH),\n",
    "        'exist_ok': True,\n",
    "        'pretrained': True,\n",
    "        'patience': 30,\n",
    "        'val': True,\n",
    "        # Disable HSV augmentation (not applicable for depth)\n",
    "        'hsv_h': 0.0,\n",
    "        'hsv_s': 0.0,\n",
    "        'hsv_v': 0.0,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.1,\n",
    "        'scale': 0.5,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 1.0,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0,\n",
    "        'erasing': 0.0,\n",
    "    })\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    results_all[seed] = {\n",
    "        'model_path': str(RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nSeed {seed} completed!\")\n",
    "    \n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 9: Evaluation on Test Set\n",
    "# =============================================================================\n",
    "results_dict = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    \n",
    "    model = YOLO(str(model_path))\n",
    "    \n",
    "    # Convert to 4ch if needed\n",
    "    first_conv = model.model.model[0].conv\n",
    "    if first_conv.in_channels == 3:\n",
    "        print(\"  Converting to 4ch...\")\n",
    "        model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "    \n",
    "    # Verify 4-channel\n",
    "    print(f\"  Model input channels: {model.model.model[0].conv.in_channels}\")\n",
    "    \n",
    "    metrics = model.val(\n",
    "        data=str(config_path),\n",
    "        split=\"test\",\n",
    "        device=DEVICE,\n",
    "        name=f\"test_{EXP_PREFIX}_seed{seed}\",\n",
    "        exist_ok=True,\n",
    "    )\n",
    "    \n",
    "    results_dict[seed] = {\n",
    "        'mAP50': metrics.box.map50,\n",
    "        'mAP50-95': metrics.box.map,\n",
    "        'Precision': metrics.box.mp,\n",
    "        'Recall': metrics.box.mr\n",
    "    }\n",
    "    \n",
    "    print(f\"  mAP50: {metrics.box.map50:.3f}, mAP50-95: {metrics.box.map:.3f}\")\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 10: Results Summary\n",
    "# =============================================================================\n",
    "if results_dict:\n",
    "    df = pd.DataFrame(results_dict).T\n",
    "    df.index.name = 'Seed'\n",
    "    avg = df.mean()\n",
    "    std = df.std()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"A.4b RGB+SYNTHETIC DEPTH (4-CH) - FINAL RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"SUMMARY (Mean +/- Std)\")\n",
    "    print(\"-\"*60)\n",
    "    for col in df.columns:\n",
    "        print(f\"  {col}: {avg[col]:.3f} +/- {std[col]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 11: Save Results\n",
    "# =============================================================================\n",
    "output_file = KAGGLE_OUTPUT / 'a4b_rgbd_synthetic_results.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"A.4b RGB+Synthetic Depth (4-Channel) Results - FIXED\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(\"Training: epochs=100, patience=30, other=default\\n\")\n",
    "    f.write(f\"Seeds: {SEEDS}\\n\")\n",
    "    f.write(\"4-Channel Support: YES (Custom Trainer)\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    f.write(\"Per-Seed Results:\\n\")\n",
    "    f.write(df.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "    f.write(\"\\n\\n\" + \"-\"*60 + \"\\n\")\n",
    "    f.write(\"Summary (Mean +/- Std):\\n\")\n",
    "    for col in df.columns:\n",
    "        f.write(f\"  {col}: {avg[col]:.3f} +/- {std[col]:.3f}\\n\")\n",
    "\n",
    "print(f\"Results saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 12: Create Archives\n",
    "# =============================================================================\n",
    "if RUNS_PATH.exists():\n",
    "    shutil.make_archive(str(BASE_PATH / 'a4b_runs'), 'zip', RUNS_PATH)\n",
    "    print(f\"a4b_runs.zip: {os.path.getsize(str(BASE_PATH / 'a4b_runs.zip'))/1024/1024:.1f} MB\")\n",
    "\n",
    "shutil.make_archive(str(BASE_PATH / 'a4b_output'), 'zip', KAGGLE_OUTPUT)\n",
    "print(\"a4b_output.zip created\")\n",
    "\n",
    "print(\"\\nDownload from Output tab:\")\n",
    "print(\"  - a4b_runs.zip (training runs)\")\n",
    "print(\"  - a4b_output.zip (results)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
