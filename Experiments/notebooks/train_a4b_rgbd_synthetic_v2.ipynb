{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.4b RGB + Synthetic Depth 4-Channel with Reset BN\n",
    "\n",
    "**Experiment:** A.4b - RGB+Synthetic Depth Fusion\n",
    "**Input:** RGB + Synthetic Depth (4-channel RGBD)\n",
    "**Objective:** Test fusion of RGB with synthetic depth (Depth-Anything-V2)\n",
    "**Classes:** 1 (fresh_fruit_bunch)\n",
    "\n",
    "## Key Features\n",
    "1. **4-Channel Input**: RGB (3) + Synthetic Depth (1) = 4 channels\n",
    "2. **Custom Trainer**: RGBD4ChTrainer with 4-channel support\n",
    "3. **Monkey-Patch**: Modified imread for 4-channel image loading\n",
    "4. **First Conv Adaptation**: Convert 3ch to 4ch input layer\n",
    "5. **Reset BN**: Domain adaptation for RGBD input\n",
    "\n",
    "## Prerequisites\n",
    "- Upload RGB dataset as: `ffb-localization-dataset`\n",
    "- Upload Synthetic Depth dataset as: `ffb-synthetic-depth`\n",
    "\n",
    "## Uniform Augmentation (All Experiments)\n",
    "- translate: 0.1\n",
    "- scale: 0.5\n",
    "- fliplr: 0.5\n",
    "- hsv_h: 0.0 (disabled for uniformity)\n",
    "- hsv_s: 0.0 (disabled for uniformity)\n",
    "- hsv_v: 0.0 (disabled for uniformity)\n",
    "- erasing: 0.0\n",
    "- mosaic: 0.0\n",
    "- mixup: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 1: Setup & Install\n",
    "# =============================================================================\n",
    "!pip install -q ultralytics\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Auto-detect environment\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') or os.path.exists('/kaggle')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    BASE_PATH = Path('/kaggle/working')\n",
    "    RGB_DATASET = Path('/kaggle/input/ffb-localization-dataset/ffb_localization')\n",
    "    DEPTH_DATASET = Path('/kaggle/input/ffb-synthetic-depth')\n",
    "else:\n",
    "    BASE_PATH = Path('D:/Work/Assisten Dosen/Anylabel/Experiments')\n",
    "    RGB_DATASET = BASE_PATH / 'datasets' / 'ffb_localization'\n",
    "    DEPTH_DATASET = BASE_PATH / 'datasets' / 'ffb_localization_depth_synthetic'\n",
    "\n",
    "RUNS_PATH = BASE_PATH / 'runs' / 'detect'\n",
    "RGBD_DATASET = BASE_PATH / 'rgbd_synthetic_4ch'\n",
    "KAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\n",
    "KAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"A.4b RGB+SYNTHETIC DEPTH (4-CH) - ENVIRONMENT SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "print(f\"RGB Dataset: {RGB_DATASET}\")\n",
    "print(f\"Depth Dataset: {DEPTH_DATASET}\")\n",
    "print(f\"Output RGBD: {RGBD_DATASET}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Configuration AUGMENT_PARAMS\n",
    "# =============================================================================\n",
    "# Uniform augmentation parameters (consistent across all experiments)\n",
    "AUGMENT_PARAMS = {\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'hsv_h': 0.0,  # Disabled for uniformity\n",
    "    'hsv_s': 0.0,  # Disabled for uniformity\n",
    "    'hsv_v': 0.0,  # Disabled for uniformity\n",
    "    'erasing': 0.0,\n",
    "    'mosaic': 0.0,\n",
    "    'mixup': 0.0,\n",
    "    'degrees': 0.0,\n",
    "    'copy_paste': 0.0,\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "SEEDS = [42, 123, 456, 789, 101]\n",
    "EXP_PREFIX = 'exp_a4b_rgbd_synth_v2'\n",
    "EPOCHS = 100\n",
    "PATIENCE = 30\n",
    "IMGSZ = 640\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Experiment: A.4b RGB+Synthetic Depth (4-CH) (V2)\")\n",
    "print(f\"Model: YOLOv11n\")\n",
    "print(f\"Seeds: {SEEDS} ({len(SEEDS)} runs)\")\n",
    "print(f\"Epochs: {EPOCHS} (patience: {PATIENCE})\")\n",
    "print(f\"Image Size: {IMGSZ}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"\\nUniform Augmentation:\")\n",
    "for key, value in AUGMENT_PARAMS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\nSpecial Features:\")\n",
    "print(\"  - 4-Channel input (RGB+Synthetic Depth)\")\n",
    "print(\"  - Custom 4-channel trainer\")\n",
    "print(\"  - Reset BatchNorm for domain adaptation\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Helper functions - convert_conv_to_4ch() and reset_bn_stats()\n",
    "# =============================================================================\n",
    "def convert_conv_to_4ch(conv_layer):\n",
    "    \"\"\"\n",
    "    Convert a conv layer from 3ch to 4ch input.\n",
    "    Copies RGB weights and initializes depth channel as mean of RGB.\n",
    "    \"\"\"\n",
    "    if conv_layer.in_channels == 4:\n",
    "        return conv_layer\n",
    "    \n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=4,\n",
    "        out_channels=conv_layer.out_channels,\n",
    "        kernel_size=conv_layer.kernel_size,\n",
    "        stride=conv_layer.stride,\n",
    "        padding=conv_layer.padding,\n",
    "        bias=conv_layer.bias is not None\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        new_conv.weight[:, :3, :, :] = conv_layer.weight.clone()\n",
    "        new_conv.weight[:, 3:4, :, :] = conv_layer.weight.mean(dim=1, keepdim=True)\n",
    "        if conv_layer.bias is not None:\n",
    "            new_conv.bias = nn.Parameter(conv_layer.bias.clone())\n",
    "    \n",
    "    return new_conv\n",
    "\n",
    "\n",
    "def reset_bn_stats(model, train_loader, num_batches=100, device='cuda'):\n",
    "    \"\"\"Reset running stats BatchNorm dengan 100 batch training data.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.reset_running_stats()\n",
    "            module.momentum = 0.1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            imgs = batch['img'].to(device) if isinstance(batch, dict) else batch[0].to(device)\n",
    "            _ = model(imgs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def ensure_model_4ch(model):\n",
    "    \"\"\"Ensure model has 4-channel input.\"\"\"\n",
    "    try:\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'model'):\n",
    "            first_conv = model.model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting model...\")\n",
    "                model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "        elif hasattr(model, 'model') and hasattr(model.model[0], 'conv'):\n",
    "            first_conv = model.model[0].conv\n",
    "            if first_conv.in_channels == 3:\n",
    "                print(\"[4ch] Converting model...\")\n",
    "                model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f\"[4ch] Warning: {e}\")\n",
    "    return False\n",
    "\n",
    "print(\"âœ“ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Create 4-Channel RGBD Dataset for Synthetic Depth\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING 4-CHANNEL RGBD DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nProcessing {split.upper()}...\")\n",
    "    \n",
    "    rgb_img_dir = RGB_DATASET / 'images' / split\n",
    "    depth_img_dir = DEPTH_DATASET / 'images' / split\n",
    "    rgb_lbl_dir = RGB_DATASET / 'labels' / split\n",
    "    \n",
    "    # Create output directories\n",
    "    rgbd_img_dir = RGBD_DATASET / 'images' / split\n",
    "    rgbd_lbl_dir = RGBD_DATASET / 'labels' / split\n",
    "    rgbd_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    rgbd_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get RGB files\n",
    "    rgb_files = sorted(list(rgb_img_dir.glob('*.png')))\n",
    "    \n",
    "    for rgb_path in tqdm(rgb_files, desc=f\"Creating 4-ch ({split})\"):\n",
    "        # Load RGB (3 channels)\n",
    "        rgb = cv2.imread(str(rgb_path))\n",
    "        if rgb is None:\n",
    "            print(f\"  Warning: Could not read {rgb_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Load synthetic depth (1 channel)\n",
    "        depth_path = depth_img_dir / rgb_path.name\n",
    "        depth = cv2.imread(str(depth_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if depth is None:\n",
    "            print(f\"  Warning: Could not read {depth_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Resize depth if needed\n",
    "        if depth.shape[:2] != rgb.shape[:2]:\n",
    "            depth = cv2.resize(depth, (rgb.shape[1], rgb.shape[0]))\n",
    "        \n",
    "        # Combine RGB (3) + Depth (1) = 4 channels\n",
    "        depth_expanded = depth[:, :, np.newaxis]\n",
    "        rgbd_4ch = np.concatenate([rgb, depth_expanded], axis=2)\n",
    "        \n",
    "        # Save 4-channel image\n",
    "        output_img_path = rgbd_img_dir / rgb_path.name\n",
    "        cv2.imwrite(str(output_img_path), rgbd_4ch)\n",
    "    \n",
    "    # Copy labels\n",
    "    label_files = list(rgb_lbl_dir.glob('*.txt'))\n",
    "    for lbl_path in label_files:\n",
    "        shutil.copy(str(lbl_path), str(rgbd_lbl_dir / lbl_path.name))\n",
    "    \n",
    "    img_count = len(list(rgbd_img_dir.glob('*.png')))\n",
    "    lbl_count = len(list(rgbd_lbl_dir.glob('*.txt')))\n",
    "    print(f\"  Done: {img_count} images, {lbl_count} labels\")\n",
    "\n",
    "# Verify sample\n",
    "sample_img = list((RGBD_DATASET / 'images' / 'train').glob('*.png'))[0]\n",
    "img = cv2.imread(str(sample_img), cv2.IMREAD_UNCHANGED)\n",
    "print(f\"\\nâœ“ Sample image shape: {img.shape} (should be H x W x 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Cell 5: Custom RGBD4ChTrainer and RGBD4ChValidator classes\n# =============================================================================\nimport ultralytics.utils.patches as patches\n\n_original_imread = patches.imread\n\ndef imread_4ch(filename, flags=cv2.IMREAD_UNCHANGED):\n    \"\"\"Always read with IMREAD_UNCHANGED to preserve 4 channels\"\"\"\n    return _original_imread(filename, cv2.IMREAD_UNCHANGED)\n\npatches.imread = imread_4ch\nprint(\"âœ“ Patched imread for 4-channel support\")\n\nfrom ultralytics import YOLO\nfrom ultralytics.models.yolo.detect import DetectionTrainer, DetectionValidator\nfrom ultralytics.nn.tasks import DetectionModel\nimport torch\nprint(\"âœ“ YOLO imported\")\n\n\nclass RGBD4ChTrainer(DetectionTrainer):\n    \"\"\"\n    Trainer khusus untuk 4-channel RGBD dengan BN reset menggunakan gambar training asli.\n    Sesuai catatan dosen: forward pass 100 gambar training sebelum mulai training.\n    \"\"\"\n    def __init__(self, overrides=None):\n        super().__init__(overrides=overrides)  # Fix: explicit keyword argument\n        # Register callback untuk BN reset setelah setup selesai\n        self.add_callback(\"on_train_start\", self._bn_reset_callback)\n        self._bn_reset_done = False\n    \n    def get_model(self, cfg=None, weights=None, verbose=True):\n        \"\"\"Load model dan modifikasi first conv layer untuk 4 channels.\"\"\"\n        model = super().get_model(cfg, weights, verbose)\n\n        # Modifikasi first conv layer dari 3ch ke 4ch\n        first_conv = model.model[0].conv\n        if first_conv.in_channels == 3:\n            print(\"[Trainer] Converting first conv: 3ch â†’ 4ch...\")\n            model.model[0].conv = convert_conv_to_4ch(first_conv)\n            print(f\"[Trainer] âœ… Converted! Shape: {model.model[0].conv.weight.shape}\")\n        else:\n            print(\"[Trainer] Model sudah 4-channel\")\n\n        return model\n    \n    def build_dataset(self, img_path, mode=\"train\", batch=None):\n        \"\"\"Override: gunakan RGBDDataset yang load 4 channel.\"\"\"\n        from ultralytics.data.dataset import YOLODataset\n        import cv2\n        import numpy as np\n        from pathlib import Path\n        \n        class RGBDDataset(YOLODataset):\n            \"\"\"Dataset yang load 4-channel RGBD images.\"\"\"\n            def load_image(self, i):\n                \"\"\"Load 4-channel image.\"\"\"\n                im = cv2.imread(self.im_files[i], cv2.IMREAD_UNCHANGED)\n                if im is None:\n                    raise FileNotFoundError(f\"Image Not Found {self.im_files[i]}\")\n                \n                # Ensure 4 channels\n                if len(im.shape) == 2:\n                    im = cv2.cvtColor(im, cv2.COLOR_GRAY2BGR)\n                    im = np.dstack([im, im[:,:,0]])\n                elif im.shape[2] == 3:\n                    depth_channel = np.zeros((im.shape[0], im.shape[1], 1), dtype=np.uint8)\n                    im = np.dstack([im, depth_channel])\n                \n                h0, w0 = im.shape[:2]\n                r = self.imgsz / max(h0, w0)\n                if r != 1:\n                    interp = cv2.INTER_LINEAR if r > 1 else cv2.INTER_AREA\n                    im = cv2.resize(im, (int(w0 * r), int(h0 * r)), interpolation=interp)\n                \n                return im, (h0, w0), im.shape[:2]\n        \n        return RGBDDataset(\n            img_path=img_path,\n            imgsz=self.args.imgsz,\n            batch_size=batch,\n            augment=mode == \"train\",\n            hyp=self.args,\n            rect=mode == \"val\",\n            cache=self.args.cache,\n            single_cls=self.args.single_cls,\n            stride=max(self.model.stride) if hasattr(self.model, 'stride') else 32,\n            pad=0.0 if mode == \"train\" else 0.5,\n            prefix=f\"{mode}: \",\n        )\n    \n    def _bn_reset_callback(self, trainer):\n        \"\"\"\n        Callback: Reset BatchNorm dengan forward pass 100 gambar training.\n        Dipanggil otomatis saat on_train_start.\n        \"\"\"\n        if self._bn_reset_done:\n            return\n            \n        print(f\"\\n[BN Reset] Resetting BatchNorm dengan 100 gambar training...\")\n        \n        # 1. Reset running stats\n        bn_layers = []\n        for module in self.model.modules():\n            if isinstance(module, nn.BatchNorm2d):\n                module.reset_running_stats()\n                module.momentum = 0.1\n                bn_layers.append(module)\n        print(f\"[BN Reset] Found {len(bn_layers)} BatchNorm layers\")\n        \n        # 2. Set model to train mode\n        self.model.train()\n        \n        # 3. Forward pass dengan 100 gambar training asli\n        device = next(self.model.parameters()).device\n        images_processed = 0\n        n_images = 100\n        \n        with torch.no_grad():\n            for batch in self.train_loader:\n                if images_processed >= n_images:\n                    break\n                \n                images = batch['img'].to(device, non_blocking=True)\n                print(f\"[BN Reset] Batch shape: {images.shape}, dtype: {images.dtype}\")\n                \n                # Forward pass - update BN running stats\n                _ = self.model(images)\n                \n                images_processed += len(images)\n        \n        print(f\"[BN Reset] âœ… Completed forward pass pada {images_processed} gambar\")\n        \n        # 4. Verify BN stats\n        if bn_layers:\n            sample_bn = bn_layers[0]\n            print(f\"[BN Reset] Sample BN running_mean: [{sample_bn.running_mean.min():.4f}, {sample_bn.running_mean.max():.4f}]\")\n        \n        self._bn_reset_done = True\n\n    def get_validator(self):\n        self.loss_names = \"box_loss\", \"cls_loss\", \"dfl_loss\"\n        return RGBD4ChValidator(\n            self.test_loader,\n            save_dir=self.save_dir,\n            args=self.args,\n            _callbacks=self.callbacks\n        )\n\n\nclass RGBD4ChValidator(DetectionValidator):\n    \"\"\"Validator yang convert model ke 4ch dan pakai RGBDDataset.\"\"\"\n    \n    def build_dataset(self, img_path, mode=\"val\", batch=None):\n        \"\"\"Override: gunakan RGBDDataset yang load 4 channel.\"\"\"\n        from ultralytics.data.dataset import YOLODataset\n        import cv2\n        import numpy as np\n        \n        class RGBDDataset(YOLODataset):\n            \"\"\"Dataset yang load 4-channel RGBD images.\"\"\"\n            def load_image(self, i):\n                \"\"\"Load 4-channel image.\"\"\"\n                im = cv2.imread(self.im_files[i], cv2.IMREAD_UNCHANGED)\n                if im is None:\n                    raise FileNotFoundError(f\"Image Not Found {self.im_files[i]}\")\n                \n                # Ensure 4 channels\n                if len(im.shape) == 2:\n                    im = cv2.cvtColor(im, cv2.COLOR_GRAY2BGR)\n                    im = np.dstack([im, im[:,:,0]])\n                elif im.shape[2] == 3:\n                    depth_channel = np.zeros((im.shape[0], im.shape[1], 1), dtype=np.uint8)\n                    im = np.dstack([im, depth_channel])\n                \n                h0, w0 = im.shape[:2]\n                r = self.imgsz / max(h0, w0)\n                if r != 1:\n                    interp = cv2.INTER_LINEAR if r > 1 else cv2.INTER_AREA\n                    im = cv2.resize(im, (int(w0 * r), int(h0 * r)), interpolation=interp)\n                \n                return im, (h0, w0), im.shape[:2]\n        \n        return RGBDDataset(\n            img_path=img_path,\n            imgsz=self.args.imgsz,\n            batch_size=batch,\n            augment=False,\n            hyp=self.args,\n            rect=True,\n            cache=self.args.cache if hasattr(self.args, 'cache') else False,\n            single_cls=self.args.single_cls if hasattr(self.args, 'single_cls') else False,\n            stride=int(self.stride) if hasattr(self, 'stride') else 32,\n            pad=0.5,\n            prefix=f\"{mode}: \",\n        )\n    \n    def setup_model(self):\n        super().setup_model()\n        if self.model is not None:\n            ensure_model_4ch(self.model)\n            print(\"[Validator] Model 4ch ready\")\n\n\nprint(\"âœ… Custom Trainer & Validator defined\")\nprint(\"   - Auto-convert 3ch â†’ 4ch di get_model()\")\nprint(\"   - build_dataset() override untuk 4-channel RGBDDataset\")\nprint(\"   - BN reset dengan 100 gambar training asli via callback on_train_start\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Create 4ch dataset and YAML\n",
    "# =============================================================================\n",
    "yaml_content = f\"\"\"\n",
    "# A.4b RGB+Synthetic Depth 4-Channel Dataset Configuration\n",
    "path: {RGBD_DATASET}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: 1\n",
    "channels: 4\n",
    "\n",
    "names:\n",
    "  0: fresh_fruit_bunch\n",
    "\"\"\"\n",
    "\n",
    "config_path = RGBD_DATASET / 'dataset_rgbd_synthetic_v2.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"âœ… Config saved: {config_path}\")\n",
    "print(\"\\nConfig contents:\")\n",
    "print(\"-\"*40)\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Cell 7: Training loop (Simplified - BN reset handled in trainer)\n# =============================================================================\nresults_all = {}\ntraining_times = {}\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING LOOP\")\nprint(\"=\"*60)\n\nfor idx, seed in enumerate(SEEDS, 1):\n    start_time = time.time()\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING A.4b RGBD SYNTHETIC - Seed {seed} ({idx}/{len(SEEDS)})\")\n    print(f\"{'='*60}\")\n    \n    # Set seeds\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    \n    try:\n        # Create trainer - 4ch conversion dan BN reset otomatis di get_model()\n        trainer = RGBD4ChTrainer(overrides={\n            'model': 'yolo11n.pt',\n            'data': str(config_path),\n            'imgsz': IMGSZ,\n            'epochs': EPOCHS,\n            'batch': BATCH_SIZE,\n            'device': DEVICE,\n            'seed': seed,\n            'name': f\"{EXP_PREFIX}_seed{seed}\",\n            'project': str(RUNS_PATH),\n            'exist_ok': True,\n            'pretrained': True,\n            'patience': PATIENCE,\n            'val': True,\n            **AUGMENT_PARAMS,\n        })\n        \n        # Train - conversion 4ch dan BN reset sudah dilakukan di get_model()\n        trainer.train()\n        \n        elapsed = time.time() - start_time\n        training_times[seed] = elapsed\n        \n        results_all[seed] = {\n            'model_path': str(RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"),\n            'epochs_trained': EPOCHS,\n            'completed': True,\n        }\n        \n        print(f\"\\nâœ“ Seed {seed} completed!\")\n        print(f\"  Time: {elapsed/60:.1f} minutes\")\n        \n    except Exception as e:\n        print(f\"\\nâœ— Seed {seed} failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        results_all[seed] = {'error': str(e), 'completed': False}\n    \n    # Cleanup\n    if 'trainer' in locals():\n        del trainer\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING LOOP COMPLETED\")\nprint(\"=\"*60)\n\n# Print summary\nprint(\"\\nðŸ“Š RESULTS SUMMARY:\")\nsuccessful = sum(1 for r in results_all.values() if r.get('completed', False))\nprint(f\"Successful: {successful}/{len(SEEDS)}\")\nfor seed, res in results_all.items():\n    if res.get('completed', False):\n        print(f\"  Seed {seed}: âœ“ Completed\")\n    else:\n        print(f\"  Seed {seed}: âœ— FAILED - {res.get('error', 'Unknown')[:50]}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 8: Evaluation\n",
    "# =============================================================================\n",
    "results_dict = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = RUNS_PATH / f\"{EXP_PREFIX}_seed{seed}\" / \"weights\" / \"best.pt\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(str(model_path))\n",
    "        \n",
    "        # Convert to 4ch if needed\n",
    "        first_conv = model.model.model[0].conv\n",
    "        if first_conv.in_channels == 3:\n",
    "            print(\"  Converting to 4ch...\")\n",
    "            model.model.model[0].conv = convert_conv_to_4ch(first_conv)\n",
    "        \n",
    "        # Verify 4-channel\n",
    "        print(f\"  Model input channels: {model.model.model[0].conv.in_channels}\")\n",
    "        \n",
    "        metrics = model.val(\n",
    "            data=str(config_path),\n",
    "            split=\"test\",\n",
    "            device=DEVICE,\n",
    "            name=f\"test_{EXP_PREFIX}_seed{seed}\",\n",
    "            exist_ok=True,\n",
    "        )\n",
    "        \n",
    "        results_dict[seed] = {\n",
    "            'mAP50': metrics.box.map50,\n",
    "            'mAP50-95': metrics.box.map,\n",
    "            'Precision': metrics.box.mp,\n",
    "            'Recall': metrics.box.mr,\n",
    "        }\n",
    "        \n",
    "        print(f\"  mAP50: {metrics.box.map50:.4f}, mAP50-95: {metrics.box.map:.4f}\")\n",
    "        \n",
    "        del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Evaluation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 9: Summary\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "if results_dict:\n",
    "    df = pd.DataFrame(results_dict).T\n",
    "    df.index.name = 'Seed'\n",
    "    \n",
    "    avg = df.mean()\n",
    "    std = df.std()\n",
    "    min_vals = df.min()\n",
    "    max_vals = df.max()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"A.4b RGB+SYNTHETIC DEPTH (4-CH) (V2) - FINAL RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"STATISTICAL SUMMARY\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"{'Metric':<15} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n",
    "    print(\"-\"*60)\n",
    "    for col in df.columns:\n",
    "        print(f\"{col:<15} {avg[col]:>10.4f} {std[col]:>10.4f} {min_vals[col]:>10.4f} {max_vals[col]:>10.4f}\")\n",
    "    \n",
    "    best_seed = df['mAP50'].idxmax()\n",
    "    print(f\"\\nâœ“ Best Seed: {best_seed} (mAP50: {df.loc[best_seed, 'mAP50']:.4f})\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 10: Save results\n",
    "# =============================================================================\n",
    "output_file = KAGGLE_OUTPUT / 'a4b_rgbd_synthetic_v2_results.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"A.4b RGB+Synthetic Depth (4-CH) (V2) Results\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Local'}\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Configuration:\\n\")\n",
    "    f.write(f\"  Model: YOLOv11n\\n\")\n",
    "    f.write(f\"  Input: 4-Channel (RGB+Synthetic Depth)\\n\")\n",
    "    f.write(f\"  Depth Source: Depth-Anything-V2\\n\")\n",
    "    f.write(f\"  Epochs: {EPOCHS} (patience: {PATIENCE})\\n\")\n",
    "    f.write(f\"  Image Size: {IMGSZ}\\n\")\n",
    "    f.write(f\"  Batch Size: {BATCH_SIZE}\\n\")\n",
    "    f.write(f\"  Seeds: {SEEDS}\\n\")\n",
    "    f.write(\"\\nUniform Augmentation:\\n\")\n",
    "    for key, value in AUGMENT_PARAMS.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "    f.write(\"\\nSpecial Features:\\n\")\n",
    "    f.write(\"  - 4-Channel input (RGB+Synthetic Depth)\\n\")\n",
    "    f.write(\"  - Custom RGBD4ChTrainer\\n\")\n",
    "    f.write(\"  - Reset BatchNorm for domain adaptation\\n\")\n",
    "    \n",
    "    if results_dict:\n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"Per-Seed Results:\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "        \n",
    "        f.write(\"\\n\\n\" + \"-\"*60 + \"\\n\")\n",
    "        f.write(\"Summary (Mean Â± Std):\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        for col in df.columns:\n",
    "            f.write(f\"  {col}: {avg[col]:.4f} Â± {std[col]:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Seed: {best_seed}\\n\")\n",
    "\n",
    "print(f\"\\nâœ“ Results saved: {output_file}\")\n",
    "\n",
    "# JSON output\n",
    "json_output = {\n",
    "    'experiment': 'A.4b',\n",
    "    'variant': 'V2',\n",
    "    'seeds': SEEDS,\n",
    "    'config': {\n",
    "        'model': 'yolo11n',\n",
    "        'input_channels': 4,\n",
    "        'depth_source': 'synthetic',\n",
    "        'epochs': EPOCHS,\n",
    "        'patience': PATIENCE,\n",
    "        'imgsz': IMGSZ,\n",
    "        'batch': BATCH_SIZE,\n",
    "        'augmentation': AUGMENT_PARAMS,\n",
    "        'reset_bn': True,\n",
    "    },\n",
    "    'results': {str(k): v for k, v in results_dict.items()},\n",
    "    'summary': {\n",
    "        'mean': {k: float(v) for k, v in avg.items()},\n",
    "        'std': {k: float(v) for k, v in std.items()},\n",
    "        'best_seed': int(best_seed) if results_dict else None,\n",
    "    } if results_dict else None,\n",
    "}\n",
    "\n",
    "json_file = KAGGLE_OUTPUT / 'a4b_rgbd_synthetic_v2_results.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(json_output, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ JSON saved: {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 11: Create archives\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING ARCHIVES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if RUNS_PATH.exists():\n",
    "    runs_zip = BASE_PATH / 'a4b_rgbd_synthetic_v2_runs.zip'\n",
    "    shutil.make_archive(str(runs_zip.with_suffix('')), 'zip', RUNS_PATH)\n",
    "    size_mb = runs_zip.stat().st_size / 1024 / 1024\n",
    "    print(f\"âœ“ a4b_rgbd_synthetic_v2_runs.zip: {size_mb:.1f} MB\")\n",
    "\n",
    "output_zip = BASE_PATH / 'a4b_rgbd_synthetic_v2_output.zip'\n",
    "shutil.make_archive(str(output_zip.with_suffix('')), 'zip', KAGGLE_OUTPUT)\n",
    "size_mb = output_zip.stat().st_size / 1024 / 1024\n",
    "print(f\"âœ“ a4b_rgbd_synthetic_v2_output.zip: {size_mb:.1f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL DONE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDownload from Output tab:\")\n",
    "print(\"  - a4b_rgbd_synthetic_v2_runs.zip (training runs)\")\n",
    "print(\"  - a4b_rgbd_synthetic_v2_output.zip (results)\")"
   ]
  }
 ]
}