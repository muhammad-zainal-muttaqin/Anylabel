{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# B.2 - Two-Stage Ripeness Classification\n",
    "\n",
    "**Experiment:** B.2  \n",
    "**Approach:** Detect → Crop → Classify (2 stages)  \n",
    "**Objective:** Test if separating detection and classification improves accuracy  \n",
    "**Classes:** 2 (ripe, unripe)\n",
    "\n",
    "## Pipeline\n",
    "1. **Stage 1**: Detector - Detect all FFBs (ripe/unripe)\n",
    "2. **Crop**: Extract bounding boxes with 10% margin\n",
    "3. **Stage 2**: Classifier - Classify crops\n",
    "4. **Evaluation**: End-to-end pipeline on test set\n",
    "\n",
    "## Training Config\n",
    "- Stage 1 (Detection): YOLOv11n, epochs=100, patience=30\n",
    "- Stage 2 (Classification): YOLOv11n-cls, epochs=100, patience=30\n",
    "- Seeds: 5 (42, 123, 456, 789, 101)\n",
    "- Other parameters: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 1: Setup\n",
    "# =============================================================================\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = Path('/kaggle/input/ffb-ripeness-detect')\n",
    "BASE_PATH = Path('/kaggle/working')\n",
    "RUNS_PATH = BASE_PATH / 'runs'\n",
    "CROPS_PATH = BASE_PATH / 'crops'\n",
    "KAGGLE_OUTPUT = BASE_PATH / 'kaggleoutput'\n",
    "KAGGLE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset: {DATASET_PATH} (exists: {DATASET_PATH.exists()})\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Verify dataset\n",
    "for split in ['train', 'val', 'test']:\n",
    "    imgs = len(list((DATASET_PATH / 'images' / split).glob('*.png')))\n",
    "    lbls = len(list((DATASET_PATH / 'labels' / split).glob('*.txt')))\n",
    "    print(f\"  {split}: {imgs} images, {lbls} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yaml-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Create YAML for Stage 1 (Detection)\n",
    "# =============================================================================\n",
    "%%writefile /kaggle/working/dataset_stage1.yaml\n",
    "# B.2 Stage 1 - Detection (2 Classes)\n",
    "path: /kaggle/input/ffb-ripeness-detect\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: 2\n",
    "names: ['ripe', 'unripe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Install Dependencies\n",
    "# =============================================================================\n",
    "!pip install -q ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "print(\"Ultralytics ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Training Config\n",
    "# =============================================================================\n",
    "SEEDS = [42, 123, 456, 789, 101]\n",
    "STAGE1_PREFIX = 'exp_b2_stage1'\n",
    "STAGE2_PREFIX = 'exp_b2_stage2'\n",
    "\n",
    "stage1_config_path = Path('/kaggle/working/dataset_stage1.yaml')\n",
    "\n",
    "print(f\"Seeds: {SEEDS} ({len(SEEDS)} runs)\")\n",
    "print(\"Pipeline: Detect -> Crop -> Classify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stage1-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Stage 1 - Train Detector (5 seeds)\n",
    "# =============================================================================\n",
    "stage1_models = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"STAGE 1 (DETECTOR) - Seed {seed} ({SEEDS.index(seed)+1}/{len(SEEDS)})\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    model = YOLO('yolo11n.pt')\n",
    "    \n",
    "    results = model.train(\n",
    "        data=str(stage1_config_path),\n",
    "        epochs=100,\n",
    "        patience=30,\n",
    "        seed=seed,\n",
    "        name=f\"{STAGE1_PREFIX}_seed{seed}\",\n",
    "        exist_ok=True,\n",
    "    )\n",
    "    \n",
    "    model_path = RUNS_PATH / 'detect' / f\"{STAGE1_PREFIX}_seed{seed}\" / 'weights' / 'best.pt'\n",
    "    stage1_models[seed] = str(model_path)\n",
    "    \n",
    "    print(f\"\\nSeed {seed} complete! Model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crop-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Crop Extraction Function\n",
    "# =============================================================================\n",
    "def extract_crops_with_margin(image_dir, label_dir, output_dir, margin=0.1):\n",
    "    \"\"\"Extract crops from ground truth labels with margin.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Create output dirs\n",
    "    for class_name in ['ripe', 'unripe']:\n",
    "        (output_dir / class_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    image_files = list(Path(image_dir).glob('*.png')) + list(Path(image_dir).glob('*.jpg'))\n",
    "    stats = {'ripe': 0, 'unripe': 0}\n",
    "    \n",
    "    for img_path in tqdm(image_files, desc=\"Extracting crops\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Get GT labels\n",
    "        label_path = Path(label_dir) / f\"{img_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:5])\n",
    "            \n",
    "            # Convert to pixel coords\n",
    "            x_center *= w\n",
    "            y_center *= h\n",
    "            width *= w\n",
    "            height *= h\n",
    "            \n",
    "            # Add margin\n",
    "            width_margin = width * margin\n",
    "            height_margin = height * margin\n",
    "            x1 = int(max(0, x_center - (width + width_margin) / 2))\n",
    "            y1 = int(max(0, y_center - (height + height_margin) / 2))\n",
    "            x2 = int(min(w, x_center + (width + width_margin) / 2))\n",
    "            y2 = int(min(h, y_center + (height + height_margin) / 2))\n",
    "            \n",
    "            # Crop\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            if crop.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Save\n",
    "            class_name = 'ripe' if class_id == 0 else 'unripe'\n",
    "            crop_filename = f\"{img_path.stem}_crop{i}.png\"\n",
    "            crop_path = output_dir / class_name / crop_filename\n",
    "            cv2.imwrite(str(crop_path), crop)\n",
    "            stats[class_name] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"Crop extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-crops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 7: Extract Crops for All Splits\n",
    "# =============================================================================\n",
    "print(\"Extracting crops from ground truth labels...\\n\")\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"{'='*40}\")\n",
    "    print(f\"Processing {split.upper()}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    img_dir = DATASET_PATH / 'images' / split\n",
    "    label_dir = DATASET_PATH / 'labels' / split\n",
    "    output_dir = CROPS_PATH / split\n",
    "    \n",
    "    stats = extract_crops_with_margin(img_dir, label_dir, output_dir, margin=0.1)\n",
    "    \n",
    "    print(f\"  Ripe: {stats['ripe']}\")\n",
    "    print(f\"  Unripe: {stats['unripe']}\")\n",
    "    print(f\"  Total: {sum(stats.values())}\\n\")\n",
    "\n",
    "print(f\"All crops saved to: {CROPS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stage2-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 8: Stage 2 - Train Classifier (5 seeds)\n",
    "# =============================================================================\n",
    "stage2_models = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"STAGE 2 (CLASSIFIER) - Seed {seed} ({SEEDS.index(seed)+1}/{len(SEEDS)})\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    model = YOLO('yolo11n-cls.pt')\n",
    "    \n",
    "    results = model.train(\n",
    "        data=str(CROPS_PATH),\n",
    "        epochs=100,\n",
    "        patience=30,\n",
    "        seed=seed,\n",
    "        imgsz=224,\n",
    "        name=f\"{STAGE2_PREFIX}_seed{seed}\",\n",
    "        exist_ok=True,\n",
    "    )\n",
    "    \n",
    "    model_path = RUNS_PATH / 'classify' / f\"{STAGE2_PREFIX}_seed{seed}\" / 'weights' / 'best.pt'\n",
    "    stage2_models[seed] = str(model_path)\n",
    "    \n",
    "    print(f\"\\nSeed {seed} complete! Model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-stage1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 9: Evaluate Stage 1 (Detection) on Test Set\n",
    "# =============================================================================\n",
    "stage1_results = {}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STAGE 1 EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = stage1_models.get(seed)\n",
    "    if not model_path or not Path(model_path).exists():\n",
    "        print(f\"Not found: seed {seed}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    model = YOLO(model_path)\n",
    "    metrics = model.val(data=str(stage1_config_path), split='test')\n",
    "    \n",
    "    stage1_results[seed] = {\n",
    "        'mAP50': metrics.box.map50,\n",
    "        'mAP50-95': metrics.box.map,\n",
    "        'Precision': metrics.box.mp,\n",
    "        'Recall': metrics.box.mr\n",
    "    }\n",
    "    \n",
    "    print(f\"  mAP50: {metrics.box.map50:.3f}\")\n",
    "    print(f\"  mAP50-95: {metrics.box.map:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-stage2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 10: Evaluate Stage 2 (Classification) on Test Crops\n",
    "# =============================================================================\n",
    "stage2_results = {}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STAGE 2 EVALUATION ON TEST CROPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model_path = stage2_models.get(seed)\n",
    "    if not model_path or not Path(model_path).exists():\n",
    "        print(f\"Not found: seed {seed}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    model = YOLO(model_path)\n",
    "    metrics = model.val(data=str(CROPS_PATH), split='test')\n",
    "    \n",
    "    stage2_results[seed] = {\n",
    "        'Top1_Acc': metrics.top1,\n",
    "        'Top5_Acc': metrics.top5\n",
    "    }\n",
    "    \n",
    "    print(f\"  Top-1 Accuracy: {metrics.top1:.3f}\")\n",
    "    print(f\"  Top-5 Accuracy: {metrics.top5:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 11: Results Summary\n",
    "# =============================================================================\n",
    "# Stage 1 Results\n",
    "df_stage1 = pd.DataFrame(stage1_results).T\n",
    "df_stage1.index.name = 'Seed'\n",
    "avg_stage1 = df_stage1.mean()\n",
    "std_stage1 = df_stage1.std()\n",
    "\n",
    "# Stage 2 Results\n",
    "df_stage2 = pd.DataFrame(stage2_results).T\n",
    "df_stage2.index.name = 'Seed'\n",
    "avg_stage2 = df_stage2.mean()\n",
    "std_stage2 = df_stage2.std()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"B.2 TWO-STAGE - STAGE 1 (DETECTION) RESULTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(df_stage1.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "print(\"\\nSUMMARY (Mean ± Std):\")\n",
    "for col in df_stage1.columns:\n",
    "    print(f\"  {col}: {avg_stage1[col]:.3f} ± {std_stage1[col]:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"B.2 TWO-STAGE - STAGE 2 (CLASSIFICATION) RESULTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(df_stage2.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "print(\"\\nSUMMARY (Mean ± Std):\")\n",
    "for col in df_stage2.columns:\n",
    "    print(f\"  {col}: {avg_stage2[col]:.3f} ± {std_stage2[col]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 12: Save Results\n",
    "# =============================================================================\n",
    "output_file = KAGGLE_OUTPUT / 'b2_twostage_results.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"B.2 Two-Stage Ripeness Classification Results\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(\"Training: epochs=100, patience=30, other=default\\n\")\n",
    "    f.write(f\"Seeds: {SEEDS}\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"STAGE 1 (Detection) Results:\\n\")\n",
    "    f.write(df_stage1.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "    f.write(\"\\n\\nStage 1 Summary (Mean ± Std):\\n\")\n",
    "    for col in df_stage1.columns:\n",
    "        f.write(f\"  {col}: {avg_stage1[col]:.3f} ± {std_stage1[col]:.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    f.write(\"STAGE 2 (Classification) Results:\\n\")\n",
    "    f.write(df_stage2.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "    f.write(\"\\n\\nStage 2 Summary (Mean ± Std):\\n\")\n",
    "    for col in df_stage2.columns:\n",
    "        f.write(f\"  {col}: {avg_stage2[col]:.3f} ± {std_stage2[col]:.3f}\\n\")\n",
    "\n",
    "print(f\"Results saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "archive-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 13: Create Archives\n",
    "# =============================================================================\n",
    "if (RUNS_PATH / 'detect').exists():\n",
    "    shutil.make_archive('/kaggle/working/b2_stage1_runs', 'zip', RUNS_PATH / 'detect')\n",
    "    print(f\"b2_stage1_runs.zip created\")\n",
    "\n",
    "if (RUNS_PATH / 'classify').exists():\n",
    "    shutil.make_archive('/kaggle/working/b2_stage2_runs', 'zip', RUNS_PATH / 'classify')\n",
    "    print(f\"b2_stage2_runs.zip created\")\n",
    "\n",
    "shutil.make_archive('/kaggle/working/b2_output', 'zip', KAGGLE_OUTPUT)\n",
    "print(\"b2_output.zip created\")\n",
    "\n",
    "print(\"\\nDownload from Output tab\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
